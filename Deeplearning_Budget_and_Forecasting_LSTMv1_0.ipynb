{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOssYKrf0MQrXA3EZjzVXUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreeshambav/DeepLearning_training/blob/main/Deeplearning_Budget_and_Forecasting_LSTMv1_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "-0HqKlbWYKn-",
        "outputId": "be39360d-ebba-4649-8f23-607595d2a676"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a52e269e-9823-4121-94cd-9b8af940ee88\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a52e269e-9823-4121-94cd-9b8af940ee88\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Budget_merged_file_Cat_with_outliers_MRL_LINE_replaced.xlsx to Budget_merged_file_Cat_with_outliers_MRL_LINE_replaced.xlsx\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(True)\n",
        "# Read the data\n",
        "# file_path = 'E:\\\\Raj\\\\Book-working\\\\10-Python\\\\Program\\\\Alpha_Optimum_Python\\\\Projects\\\\DS\\\\DL\\\\Sunoida\\\\Working_data\\\\Budget_merged_file_Cat_with_outliers_MRL_LINE_replaced.xlsx'\n",
        "# df = pd.read_excel(file_path)\n",
        "\n",
        "file_path = 'Budget_merged_file_Cat_with_outliers_MRL_LINE_replaced.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "\n",
        "# Drop rows with missing values in the specified columns\n",
        "df = df.dropna(subset=[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"])\n",
        "\n",
        "# Convert the values in columns \"01\" to \"12\" to numeric\n",
        "df[[\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]] = df[\n",
        "    [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
        "].apply(pd.to_numeric, errors=\"coerce\")\n",
        "\n",
        "# Define months and years\n",
        "months = [f\"{i:02d}\" for i in range(1, 13)]\n",
        "years = df[\"Year\"].unique()\n",
        "\n",
        "# Group the data based on categories\n",
        "grouped_df = df.groupby(\"MRL_LINE\")\n",
        "\n",
        "# Filter data for each year (2019, 2020, 2021) and apply ARIMA model for each MRL_LINE\n",
        "years = [2019, 2020, 2021, 2022]\n",
        "\n",
        "# Helper function to find the last financial year\n",
        "def find_last_financial_year(years):\n",
        "    sorted_years = sorted(years, reverse=True)\n",
        "    for i in range(len(sorted_years) - 1):\n",
        "        if sorted_years[i] - 1 != sorted_years[i + 1]:\n",
        "            return sorted_years[i]\n",
        "    return sorted_years[-1]\n",
        "\n",
        "# Initialize dataframe to store forecast results\n",
        "predicted_df = pd.DataFrame(columns=[\"MRL_LINE\", \"Year\", \"Month\", \"LSTM_Predicted_Value\"])\n",
        "forecast_df = pd.DataFrame(columns=[\"MRL_LINE\", \"Year\", \"Month\", \"LSTM_Forecasted_Value\"])\n",
        "metrics_df = pd.DataFrame(\n",
        "    columns=[\"MRL\", \"MSE\", \"RMSE\", \"MAPE\", \"z_scores_t\", \"z_scores_p\", \"R2\"]\n",
        ")\n",
        "\n",
        "# Initialize lists to store evaluation metrics\n",
        "mse_list = []\n",
        "r2_list = []\n",
        "rmse_list = []\n",
        "mape_list = []\n",
        "z_scores_list_t = []\n",
        "z_scores_list_p = []\n",
        "\n",
        "def create_sequences(data, n_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps + 1):\n",
        "        X.append(data[i:i + n_steps])\n",
        "        y.append(data[i + n_steps - 1])  # Change this line\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "#############################################################\n",
        "n_steps_train = 24  # Define the number of time steps for training sequences\n",
        "n_steps_test = 12   # Define the number of time steps for testing sequences\n",
        "\n",
        "# for mrl_line, group_df in grouped_df:\n",
        "#     print(f\"Processing MRL_LINE: {mrl_line}\")\n",
        "#     print(group_df)  # Print the group DataFrame for debugging\n",
        "\n",
        "#     for year in years:\n",
        "#         print(f\"Processing Year: {year}\")\n",
        "#         year_df = group_df[group_df['Year'] == year]\n",
        "\n",
        "#         # Check if all 12 columns exist in the DataFrame\n",
        "#         data_columns = [str(month).zfill(2) for month in range(1, 13)]\n",
        "#         missing_columns = [col for col in data_columns if col not in year_df.columns]\n",
        "\n",
        "#         if missing_columns:\n",
        "#             print(f\"Missing data columns for MRL_LINE: {mrl_line}, Year: {year}: {missing_columns}\")\n",
        "#             continue\n",
        "\n",
        "#         data = year_df[data_columns].values.flatten()\n",
        "\n",
        "#         # Handle cases where there might be missing data for some years\n",
        "#         if np.any((data != 0) & pd.notnull(data)):\n",
        "#             # Find last financial year\n",
        "#             last_financial_year = find_last_financial_year(years)\n",
        "\n",
        "#             # Split data into train and test sets\n",
        "#             if year == last_financial_year:\n",
        "#                 # Last 12 months as test data\n",
        "#                 train_data = data[:-12]\n",
        "#                 test_data = data[-12:]\n",
        "#             else:\n",
        "#                 # Rest as train data\n",
        "#                 train_data = data[:-12]  # Use all available data except the last 12 months\n",
        "#                 test_data = data[-12:]  # Use the last 12 months as test data\n",
        "#                 print(\"Printing X_train and X_test...\")\n",
        "#                 print(train_data)\n",
        "#                 print(test_data)\n",
        "\n",
        "#             # Check if there is enough data to create sequences\n",
        "#             if len(train_data) >= n_steps_train and len(test_data) >= n_steps_test:\n",
        "\n",
        "#                 print(\"Creating sequences...\")\n",
        "#                 print(len(train_data), len(test_data))\n",
        "#                 # Normalize the data\n",
        "#                 scaler = MinMaxScaler()\n",
        "#                 train_data = scaler.fit_transform(train_data.reshape(-1, 1))\n",
        "#                 test_data = scaler.transform(test_data.reshape(-1, 1))\n",
        "\n",
        "#                 # Create sequences of data\n",
        "#                 X_train, y_train = create_sequences(train_data, n_steps_train)\n",
        "#                 X_test, y_test = create_sequences(test_data, n_steps_test)\n",
        "\n",
        "#                 # Reshape the input data\n",
        "#                 X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "#                 X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "#                 print(\"Printing X_train and X_test... reshape\")\n",
        "#                 print(X_train.shape)\n",
        "#                 print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "# #################################################\n",
        "for mrl_line, group_df in grouped_df:\n",
        "    print(f\"Processing MRL_LINE: {mrl_line}\")\n",
        "    print(group_df)  # Print the group DataFrame for debugging\n",
        "\n",
        "    for year in years:\n",
        "        print(f\"Processing Year: {year}\")\n",
        "        year_df = group_df[group_df['Year'] == year]\n",
        "\n",
        "        # Check if all 12 columns exist in the DataFrame\n",
        "        data_columns = [str(month).zfill(2) for month in range(1, 13)]\n",
        "        missing_columns = [col for col in data_columns if col not in year_df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            print(f\"Missing data columns for MRL_LINE: {mrl_line}, Year: {year}: {missing_columns}\")\n",
        "            continue\n",
        "\n",
        "        data = year_df[data_columns].values.flatten()\n",
        "\n",
        "        # Handle cases where there might be missing data for some years\n",
        "        if np.any((data != 0) & pd.notnull(data)):\n",
        "            # Find last financial year\n",
        "            last_financial_year = find_last_financial_year(years)\n",
        "\n",
        "            # Split data into train and test sets\n",
        "            if year == last_financial_year:\n",
        "                # Last 12 months as test data\n",
        "                train_data = data[:-12]\n",
        "                test_data = data[-12:]\n",
        "            else:\n",
        "                # Rest as train data\n",
        "                train_data = data[:-12]  # Use all available data except the last 12 months\n",
        "                test_data = data[-12:]  # Use the last 12 months as test data\n",
        "                print(\"Printing X_train and X_test...\")\n",
        "                print(train_data)\n",
        "                print(test_data)\n",
        "\n",
        "            # Check if there is enough data to create sequences\n",
        "            if len(train_data) >= n_steps_train and len(test_data) >= n_steps_test:\n",
        "\n",
        "                print(\"Creating sequences...\")\n",
        "                print(len(train_data), len(test_data))\n",
        "                # Normalize the data\n",
        "                scaler = MinMaxScaler()\n",
        "                train_data = scaler.fit_transform(train_data.reshape(-1, 1)).flatten()  # Reshape to 1D\n",
        "                test_data = scaler.transform(test_data.reshape(-1, 1)).flatten()  # Reshape to 1D\n",
        "\n",
        "                # Create sequences of data\n",
        "                X_train, y_train = create_sequences(train_data, n_steps_train)\n",
        "                X_test, y_test = create_sequences(test_data, n_steps_test)\n",
        "\n",
        "                # Reshape the input data\n",
        "                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "                X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "                print(\"Printing X_train and X_test... reshape\")\n",
        "                print(X_train.shape)\n",
        "                print(X_test.shape)\n",
        "                # # Build the Bidirectional LSTM model\n",
        "                model = Sequential()\n",
        "                model.add(\n",
        "                    Bidirectional(LSTM(units=128, activation=\"Softmax\"), input_shape=(X_train.shape[1], X_train.shape[2]))\n",
        "                )\n",
        "                model.add(Dense(1))  # Output layer\n",
        "\n",
        "                # Compile the model\n",
        "                model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=['accuracy'])\n",
        "                print(model.summary())\n",
        "                # model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", run_eagerly=True)\n",
        "                # Early stopping to prevent overfitting\n",
        "                early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "                # Train the model\n",
        "                model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_EZXTkuYZb8",
        "outputId": "1f1bef50-63f0-4141-fc3d-36bd232e0e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_394 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing MRL_LINE: M621100\n",
            "      COUNTRY  VISION_OUC CURRENCY MRL_LINE          01          02  \\\n",
            "286        KE  KE01008014      KES  M621100        0.00        0.00   \n",
            "3184       KE  KE01008010      KES  M621100        0.00        0.00   \n",
            "3854       KE  KE01008012      KES  M621100        0.00        0.00   \n",
            "5151       KE  KE01008120      KES  M621100        0.00        0.00   \n",
            "5419       KE  KE01000999      KES  M621100        0.00        0.00   \n",
            "6913       KE  KE01008053      KES  M621100        0.00        0.00   \n",
            "8618       KE  KE01008120      KES  M621100        0.00        0.00   \n",
            "10218      KE  KE01008053      KES  M621100        0.00      201.60   \n",
            "13397      KE  KE01008010      KES  M621100        0.00  6071325.00   \n",
            "13476      KE  KE01008120      KES  M621100 -6071325.00  -508848.00   \n",
            "14595      KE  KE01008120      KES  M621100        0.00        0.00   \n",
            "15682      KE  KE01000999      KES  M621100        0.00        0.00   \n",
            "18098      KE  KE01008012      KES  M621100 -9365740.60 -9848205.70   \n",
            "18240      KE  KE0100PC07      KES  M621100  6071325.00 -6071325.00   \n",
            "18756      KE  KE01008120      KES  M621100     -192.05     -156.84   \n",
            "18757      KE  KE01008120      KES  M621100        0.00  -648460.42   \n",
            "18758      KE  KE01008053      KES  M621100        0.00 -4442669.00   \n",
            "18759      KE  KE01000999      KES  M621100 -4451144.90    -8475.90   \n",
            "18760      KE  KE01008091      KES  M621100        0.00        0.00   \n",
            "18761      KE  KE01008012      KES  M621100 -7664371.25 -8840284.00   \n",
            "18762      KE  KE01008010      KES  M621100  -165475.00  -165475.00   \n",
            "\n",
            "                 03            04            05            06  ...  \\\n",
            "286    0.000000e+00  0.000000e+00  2.630150e+05  0.000000e+00  ...   \n",
            "3184   0.000000e+00  0.000000e+00  0.000000e+00 -1.000000e+03  ...   \n",
            "3854   0.000000e+00  0.000000e+00 -6.128312e+06 -6.125314e+06  ...   \n",
            "5151   0.000000e+00  0.000000e+00  1.049962e+04  1.150342e+04  ...   \n",
            "5419   0.000000e+00  0.000000e+00 -2.092884e+04 -1.352951e+04  ...   \n",
            "6913   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
            "8618   0.000000e+00  0.000000e+00  1.000000e+06  0.000000e+00  ...   \n",
            "10218  6.882800e+02 -7.106357e+02  1.024280e+03  8.664700e+02  ...   \n",
            "13397  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
            "13476  0.000000e+00 -6.786249e+06  0.000000e+00  0.000000e+00  ...   \n",
            "14595  0.000000e+00  0.000000e+00  3.638745e+06  0.000000e+00  ...   \n",
            "15682  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
            "18098 -1.209431e+07 -1.209431e+07 -1.209431e+07 -1.209431e+07  ...   \n",
            "18240  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
            "18756 -1.591000e+02 -1.644790e+03 -2.029210e+03 -2.309300e+03  ...   \n",
            "18757  2.573616e+04 -5.691472e+06  1.832709e+04 -6.989686e+06  ...   \n",
            "18758 -4.442669e+06 -5.042507e+06 -5.345228e+06 -5.727500e+06  ...   \n",
            "18759 -1.607896e+04 -8.624600e+03 -8.624600e+03 -8.624600e+03  ...   \n",
            "18760  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
            "18761 -8.827552e+06 -9.591136e+06 -9.066822e+06 -9.082932e+06  ...   \n",
            "18762 -1.654750e+05 -3.303400e+05 -2.504350e+05 -2.298400e+05  ...   \n",
            "\n",
            "                 08            09            10            11            12  \\\n",
            "286    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "3184   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "3854  -6.321113e+06 -6.320769e+06 -6.317197e+06 -6.320929e+06 -1.194164e+07   \n",
            "5151  -3.835000e+05  2.400000e+04 -6.079187e+06  3.150000e+04  3.450000e+04   \n",
            "5419  -2.752799e+04 -2.254328e+04 -2.688605e+04 -2.537500e+04 -6.521278e+04   \n",
            "6913   0.000000e+00  0.000000e+00 -3.224209e+03  0.000000e+00  0.000000e+00   \n",
            "8618   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  1.231691e+05   \n",
            "10218  1.225880e+03  1.449880e+03  1.248280e+03  1.577150e+03  1.822540e+03   \n",
            "13397  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "13476  0.000000e+00 -2.830000e+04 -9.781676e+06  0.000000e+00 -8.117079e+06   \n",
            "14595  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "15682  0.000000e+00  0.000000e+00  0.000000e+00 -9.858439e+02 -4.442669e+06   \n",
            "18098 -9.964312e+06 -9.964312e+06 -9.964312e+06 -9.964762e+06 -6.324312e+06   \n",
            "18240  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "18756  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "18757  0.000000e+00 -5.979878e+06  0.000000e+00  0.000000e+00 -6.642690e+06   \n",
            "18758 -5.888391e+06 -5.889208e+06 -5.802514e+06 -5.888391e+06 -6.013121e+06   \n",
            "18759 -4.648990e+04 -4.648990e+04 -5.657900e+03 -7.557077e+03 -6.971502e+03   \n",
            "18760  0.000000e+00 -2.000000e+05  0.000000e+00  0.000000e+00  0.000000e+00   \n",
            "18761 -9.091574e+06 -9.085349e+06 -9.096512e+06 -8.746329e+06 -8.750250e+06   \n",
            "18762 -2.726980e+05 -2.298400e+05 -2.298400e+05  1.451600e+05 -2.298400e+05   \n",
            "\n",
            "       Year  MRL_Category_Cat1  MRL_Category_Cat2  MRL_Category_Cat3  \\\n",
            "286    2019                  1                  0                  0   \n",
            "3184   2019                  1                  0                  0   \n",
            "3854   2019                  1                  0                  0   \n",
            "5151   2019                  1                  0                  0   \n",
            "5419   2019                  1                  0                  0   \n",
            "6913   2019                  1                  0                  0   \n",
            "8618   2019                  1                  0                  0   \n",
            "10218  2020                  1                  0                  0   \n",
            "13397  2020                  1                  0                  0   \n",
            "13476  2020                  1                  0                  0   \n",
            "14595  2020                  1                  0                  0   \n",
            "15682  2020                  1                  0                  0   \n",
            "18098  2020                  1                  0                  0   \n",
            "18240  2020                  1                  0                  0   \n",
            "18756  2021                  1                  0                  0   \n",
            "18757  2021                  1                  0                  0   \n",
            "18758  2021                  1                  0                  0   \n",
            "18759  2021                  1                  0                  0   \n",
            "18760  2021                  1                  0                  0   \n",
            "18761  2021                  1                  0                  0   \n",
            "18762  2021                  1                  0                  0   \n",
            "\n",
            "       MRL_Category_Cat4  \n",
            "286                    0  \n",
            "3184                   0  \n",
            "3854                   0  \n",
            "5151                   0  \n",
            "5419                   0  \n",
            "6913                   0  \n",
            "8618                   0  \n",
            "10218                  0  \n",
            "13397                  0  \n",
            "13476                  0  \n",
            "14595                  0  \n",
            "15682                  0  \n",
            "18098                  0  \n",
            "18240                  0  \n",
            "18756                  0  \n",
            "18757                  0  \n",
            "18758                  0  \n",
            "18759                  0  \n",
            "18760                  0  \n",
            "18761                  0  \n",
            "18762                  0  \n",
            "\n",
            "[21 rows x 21 columns]\n",
            "Processing Year: 2019\n",
            "Creating sequences...\n",
            "72 12\n",
            "Printing X_train and X_test... reshape\n",
            "(49, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_395\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_394 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_394 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 496ms/step - loss: 0.7718 - accuracy: 0.0256 - val_loss: 0.9597 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 617ms/step - loss: 0.7650 - accuracy: 0.0256 - val_loss: 0.9516 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 723ms/step - loss: 0.7580 - accuracy: 0.0256 - val_loss: 0.9436 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 731ms/step - loss: 0.7512 - accuracy: 0.0256 - val_loss: 0.9355 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 0.7444 - accuracy: 0.0256 - val_loss: 0.9276 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.7376 - accuracy: 0.0256 - val_loss: 0.9197 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 453ms/step - loss: 0.7309 - accuracy: 0.0256 - val_loss: 0.9118 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 451ms/step - loss: 0.7241 - accuracy: 0.0256 - val_loss: 0.9039 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.7175 - accuracy: 0.0256 - val_loss: 0.8961 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.7109 - accuracy: 0.0256 - val_loss: 0.8884 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 0.7043 - accuracy: 0.0256 - val_loss: 0.8807 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.6978 - accuracy: 0.0256 - val_loss: 0.8731 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.6913 - accuracy: 0.0256 - val_loss: 0.8655 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 456ms/step - loss: 0.6848 - accuracy: 0.0256 - val_loss: 0.8579 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.6784 - accuracy: 0.0256 - val_loss: 0.8504 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.6719 - accuracy: 0.0256 - val_loss: 0.8428 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 648ms/step - loss: 0.6656 - accuracy: 0.0256 - val_loss: 0.8352 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 711ms/step - loss: 0.6592 - accuracy: 0.0256 - val_loss: 0.8277 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.6528 - accuracy: 0.0256 - val_loss: 0.8202 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 451ms/step - loss: 0.6464 - accuracy: 0.0256 - val_loss: 0.8128 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.6402 - accuracy: 0.0256 - val_loss: 0.8053 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 615ms/step - loss: 0.6340 - accuracy: 0.0256 - val_loss: 0.7979 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 593ms/step - loss: 0.6280 - accuracy: 0.0256 - val_loss: 0.7907 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.6218 - accuracy: 0.0256 - val_loss: 0.7836 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 447ms/step - loss: 0.6157 - accuracy: 0.0256 - val_loss: 0.7765 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 443ms/step - loss: 0.6098 - accuracy: 0.0256 - val_loss: 0.7695 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 0.6040 - accuracy: 0.0256 - val_loss: 0.7624 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 469ms/step - loss: 0.5980 - accuracy: 0.0256 - val_loss: 0.7555 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.5922 - accuracy: 0.0256 - val_loss: 0.7486 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 0.5864 - accuracy: 0.0256 - val_loss: 0.7416 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 706ms/step - loss: 0.5806 - accuracy: 0.0256 - val_loss: 0.7347 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.5748 - accuracy: 0.0256 - val_loss: 0.7278 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 455ms/step - loss: 0.5690 - accuracy: 0.0256 - val_loss: 0.7209 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.5634 - accuracy: 0.0256 - val_loss: 0.7141 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 459ms/step - loss: 0.5576 - accuracy: 0.0256 - val_loss: 0.7073 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 450ms/step - loss: 0.5521 - accuracy: 0.0256 - val_loss: 0.7006 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 460ms/step - loss: 0.5465 - accuracy: 0.0256 - val_loss: 0.6940 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.5411 - accuracy: 0.0256 - val_loss: 0.6874 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.5355 - accuracy: 0.0256 - val_loss: 0.6809 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.5302 - accuracy: 0.0256 - val_loss: 0.6744 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 449ms/step - loss: 0.5247 - accuracy: 0.0256 - val_loss: 0.6679 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 447ms/step - loss: 0.5193 - accuracy: 0.0256 - val_loss: 0.6614 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 454ms/step - loss: 0.5140 - accuracy: 0.0256 - val_loss: 0.6549 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 446ms/step - loss: 0.5086 - accuracy: 0.0256 - val_loss: 0.6484 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 465ms/step - loss: 0.5033 - accuracy: 0.0256 - val_loss: 0.6419 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 705ms/step - loss: 0.4980 - accuracy: 0.0256 - val_loss: 0.6355 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 634ms/step - loss: 0.4926 - accuracy: 0.0256 - val_loss: 0.6291 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 460ms/step - loss: 0.4874 - accuracy: 0.0256 - val_loss: 0.6227 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 0.4820 - accuracy: 0.0256 - val_loss: 0.6163 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 0.4769 - accuracy: 0.0256 - val_loss: 0.6099 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.4717 - accuracy: 0.0256 - val_loss: 0.6036 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 466ms/step - loss: 0.4665 - accuracy: 0.0256 - val_loss: 0.5974 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 460ms/step - loss: 0.4614 - accuracy: 0.0256 - val_loss: 0.5912 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.4564 - accuracy: 0.0256 - val_loss: 0.5850 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.4513 - accuracy: 0.0256 - val_loss: 0.5789 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.4464 - accuracy: 0.0256 - val_loss: 0.5728 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.4414 - accuracy: 0.0256 - val_loss: 0.5667 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 625ms/step - loss: 0.4364 - accuracy: 0.0256 - val_loss: 0.5607 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.4315 - accuracy: 0.0256 - val_loss: 0.5546 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 717ms/step - loss: 0.4268 - accuracy: 0.0256 - val_loss: 0.5486 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 712ms/step - loss: 0.4219 - accuracy: 0.0256 - val_loss: 0.5427 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.4172 - accuracy: 0.0256 - val_loss: 0.5370 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.4125 - accuracy: 0.0256 - val_loss: 0.5313 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 602ms/step - loss: 0.4080 - accuracy: 0.0256 - val_loss: 0.5257 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 0.4034 - accuracy: 0.0256 - val_loss: 0.5201 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 592ms/step - loss: 0.3989 - accuracy: 0.0256 - val_loss: 0.5145 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.3943 - accuracy: 0.0256 - val_loss: 0.5089 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 503ms/step - loss: 0.3899 - accuracy: 0.0256 - val_loss: 0.5033 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 0.3854 - accuracy: 0.0256 - val_loss: 0.4977 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 740ms/step - loss: 0.3810 - accuracy: 0.0256 - val_loss: 0.4921 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 470ms/step - loss: 0.3765 - accuracy: 0.0256 - val_loss: 0.4866 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 461ms/step - loss: 0.3722 - accuracy: 0.0256 - val_loss: 0.4813 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 0.3679 - accuracy: 0.0256 - val_loss: 0.4760 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 704ms/step - loss: 0.3637 - accuracy: 0.0256 - val_loss: 0.4708 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 0.3596 - accuracy: 0.0256 - val_loss: 0.4656 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 610ms/step - loss: 0.3554 - accuracy: 0.0256 - val_loss: 0.4604 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.3514 - accuracy: 0.0256 - val_loss: 0.4553 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 623ms/step - loss: 0.3473 - accuracy: 0.0256 - val_loss: 0.4502 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 471ms/step - loss: 0.3434 - accuracy: 0.0256 - val_loss: 0.4451 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 605ms/step - loss: 0.3393 - accuracy: 0.0256 - val_loss: 0.4401 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.3353 - accuracy: 0.0256 - val_loss: 0.4351 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 451ms/step - loss: 0.3314 - accuracy: 0.0256 - val_loss: 0.4300 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 447ms/step - loss: 0.3274 - accuracy: 0.0256 - val_loss: 0.4250 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.3237 - accuracy: 0.0256 - val_loss: 0.4201 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 465ms/step - loss: 0.3197 - accuracy: 0.0256 - val_loss: 0.4153 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 618ms/step - loss: 0.3159 - accuracy: 0.0256 - val_loss: 0.4105 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 716ms/step - loss: 0.3122 - accuracy: 0.0256 - val_loss: 0.4058 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 727ms/step - loss: 0.3085 - accuracy: 0.0256 - val_loss: 0.4010 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 445ms/step - loss: 0.3048 - accuracy: 0.0256 - val_loss: 0.3963 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.3012 - accuracy: 0.0256 - val_loss: 0.3915 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 784ms/step - loss: 0.2976 - accuracy: 0.0256 - val_loss: 0.3870 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 0.2939 - accuracy: 0.0256 - val_loss: 0.3825 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.2905 - accuracy: 0.0256 - val_loss: 0.3779 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 464ms/step - loss: 0.2869 - accuracy: 0.0256 - val_loss: 0.3734 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.2836 - accuracy: 0.0256 - val_loss: 0.3689 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 447ms/step - loss: 0.2800 - accuracy: 0.0256 - val_loss: 0.3644 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 0.2766 - accuracy: 0.0256 - val_loss: 0.3599 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 475ms/step - loss: 0.2731 - accuracy: 0.0256 - val_loss: 0.3554 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 0.2698 - accuracy: 0.0256 - val_loss: 0.3509 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 632ms/step - loss: 0.2663 - accuracy: 0.0256 - val_loss: 0.3465 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_395 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2020\n",
            "Printing X_train and X_test...\n",
            "[ 0.00000000e+00  2.01600000e+02  6.88280000e+02 -7.10635700e+02\n",
            "  1.02428000e+03  8.66470000e+02  9.72350000e+02  1.22588000e+03\n",
            "  1.44988000e+03  1.24828000e+03  1.57715000e+03  1.82254000e+03\n",
            "  0.00000000e+00  6.07132500e+06  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -6.07132500e+06 -5.08848000e+05  0.00000000e+00 -6.78624915e+06\n",
            "  0.00000000e+00  0.00000000e+00 -6.85851300e+06  0.00000000e+00\n",
            " -2.83000000e+04 -9.78167600e+06  0.00000000e+00 -8.11707900e+06\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  3.63874500e+06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -9.85843880e+02 -4.44266900e+06\n",
            " -9.36574060e+06 -9.84820570e+06 -1.20943120e+07 -1.20943120e+07\n",
            " -1.20943120e+07 -1.20943120e+07 -1.21057204e+07 -9.96431200e+06\n",
            " -9.96431200e+06 -9.96431200e+06 -9.96476151e+06 -6.32431200e+06]\n",
            "[ 6071325. -6071325.        0.        0.        0.        0.        0.\n",
            "        0.        0.        0.        0.        0.]\n",
            "Creating sequences...\n",
            "72 12\n",
            "Printing X_train and X_test... reshape\n",
            "(49, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_396\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_395 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_395 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 629ms/step - loss: 0.3815 - accuracy: 0.0000e+00 - val_loss: 0.0161 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 0.3766 - accuracy: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 441ms/step - loss: 0.3718 - accuracy: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 616ms/step - loss: 0.3670 - accuracy: 0.0000e+00 - val_loss: 0.0143 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 606ms/step - loss: 0.3623 - accuracy: 0.0000e+00 - val_loss: 0.0137 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 0.3576 - accuracy: 0.0000e+00 - val_loss: 0.0132 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.3529 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 0.3484 - accuracy: 0.0000e+00 - val_loss: 0.0123 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 0.3438 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 458ms/step - loss: 0.3393 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.3349 - accuracy: 0.0000e+00 - val_loss: 0.0111 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 614ms/step - loss: 0.3305 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 651ms/step - loss: 0.3261 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 455ms/step - loss: 0.3218 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 461ms/step - loss: 0.3175 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 613ms/step - loss: 0.3133 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 603ms/step - loss: 0.3091 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.3049 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 0.3008 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 445ms/step - loss: 0.2967 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.2926 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 609ms/step - loss: 0.2886 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.2846 - accuracy: 0.0000e+00 - val_loss: 0.0094 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 462ms/step - loss: 0.2807 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.1000\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 591ms/step - loss: 0.2768 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.1000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 730ms/step - loss: 0.2730 - accuracy: 0.0000e+00 - val_loss: 0.0097 - val_accuracy: 0.1000\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.2691 - accuracy: 0.0000e+00 - val_loss: 0.0098 - val_accuracy: 0.1000\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 595ms/step - loss: 0.2653 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.1000\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 452ms/step - loss: 0.2615 - accuracy: 0.0000e+00 - val_loss: 0.0102 - val_accuracy: 0.1000\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.2578 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.1000\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 468ms/step - loss: 0.2541 - accuracy: 0.0000e+00 - val_loss: 0.0108 - val_accuracy: 0.1000\n",
            "Processing Year: 2021\n",
            "Printing X_train and X_test...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.92050000e+02 -1.56840000e+02 -1.59100000e+02 -1.64479000e+03\n",
            " -2.02921000e+03 -2.30930000e+03 -7.05960000e+02  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00 -6.48460420e+05  2.57361564e+04 -5.69147169e+06\n",
            "  1.83270900e+04 -6.98968584e+06  0.00000000e+00  0.00000000e+00\n",
            " -5.97987800e+06  0.00000000e+00  0.00000000e+00 -6.64269000e+06\n",
            "  0.00000000e+00 -4.44266900e+06 -4.44266900e+06 -5.04250700e+06\n",
            " -5.34522835e+06 -5.72750005e+06 -5.88839100e+06 -5.88839100e+06\n",
            " -5.88920794e+06 -5.80251400e+06 -5.88839100e+06 -6.01312135e+06\n",
            " -4.45114490e+06 -8.47590000e+03 -1.60789566e+04 -8.62460000e+03\n",
            " -8.62460000e+03 -8.62460000e+03 -4.64899000e+04 -4.64899000e+04\n",
            " -4.64899000e+04 -5.65790000e+03 -7.55707696e+03 -6.97150176e+03\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -2.00000000e+05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -7.66437125e+06 -8.84028400e+06 -8.82755200e+06 -9.59113555e+06\n",
            " -9.06682208e+06 -9.08293215e+06 -9.08422240e+06 -9.09157440e+06\n",
            " -9.08534940e+06 -9.09651240e+06 -8.74632940e+06 -8.75025040e+06]\n",
            "[-165475. -165475. -165475. -330340. -250435. -229840. -229840. -272698.\n",
            " -229840. -229840.  145160. -229840.]\n",
            "Creating sequences...\n",
            "72 12\n",
            "Printing X_train and X_test... reshape\n",
            "(49, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_396 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_397\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_396 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_396 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 490ms/step - loss: 0.6718 - accuracy: 0.0000e+00 - val_loss: 0.0033 - val_accuracy: 0.1000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.6655 - accuracy: 0.0000e+00 - val_loss: 0.0029 - val_accuracy: 0.1000\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 630ms/step - loss: 0.6593 - accuracy: 0.0000e+00 - val_loss: 0.0025 - val_accuracy: 0.1000\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 453ms/step - loss: 0.6529 - accuracy: 0.0000e+00 - val_loss: 0.0022 - val_accuracy: 0.1000\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.6468 - accuracy: 0.0000e+00 - val_loss: 0.0018 - val_accuracy: 0.1000\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 594ms/step - loss: 0.6408 - accuracy: 0.0000e+00 - val_loss: 0.0016 - val_accuracy: 0.1000\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 599ms/step - loss: 0.6346 - accuracy: 0.0000e+00 - val_loss: 0.0013 - val_accuracy: 0.1000\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 596ms/step - loss: 0.6285 - accuracy: 0.0000e+00 - val_loss: 0.0011 - val_accuracy: 0.1000\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 612ms/step - loss: 0.6226 - accuracy: 0.0000e+00 - val_loss: 9.4718e-04 - val_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 607ms/step - loss: 0.6167 - accuracy: 0.0000e+00 - val_loss: 8.0662e-04 - val_accuracy: 0.1000\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 484ms/step - loss: 0.6109 - accuracy: 0.0000e+00 - val_loss: 6.9937e-04 - val_accuracy: 0.1000\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 598ms/step - loss: 0.6050 - accuracy: 0.0000e+00 - val_loss: 6.2543e-04 - val_accuracy: 0.1000\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 597ms/step - loss: 0.5991 - accuracy: 0.0000e+00 - val_loss: 5.8401e-04 - val_accuracy: 0.1000\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 0.5934 - accuracy: 0.0000e+00 - val_loss: 5.7544e-04 - val_accuracy: 0.1000\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 608ms/step - loss: 0.5875 - accuracy: 0.0000e+00 - val_loss: 5.9987e-04 - val_accuracy: 0.1000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 707ms/step - loss: 0.5818 - accuracy: 0.0000e+00 - val_loss: 6.5772e-04 - val_accuracy: 0.1000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 448ms/step - loss: 0.5761 - accuracy: 0.0000e+00 - val_loss: 7.4940e-04 - val_accuracy: 0.1000\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 440ms/step - loss: 0.5703 - accuracy: 0.0000e+00 - val_loss: 8.7544e-04 - val_accuracy: 0.1000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.5647 - accuracy: 0.0000e+00 - val_loss: 0.0010 - val_accuracy: 0.1000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 604ms/step - loss: 0.5592 - accuracy: 0.0000e+00 - val_loss: 0.0012 - val_accuracy: 0.1000\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 601ms/step - loss: 0.5534 - accuracy: 0.0000e+00 - val_loss: 0.0015 - val_accuracy: 0.1000\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 600ms/step - loss: 0.5480 - accuracy: 0.0000e+00 - val_loss: 0.0017 - val_accuracy: 0.1000\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 443ms/step - loss: 0.5425 - accuracy: 0.0000e+00 - val_loss: 0.0020 - val_accuracy: 0.1000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 449ms/step - loss: 0.5371 - accuracy: 0.0000e+00 - val_loss: 0.0023 - val_accuracy: 0.1000\n",
            "Processing Year: 2022\n",
            "Processing MRL_LINE: M623100\n",
            "      COUNTRY  VISION_OUC CURRENCY MRL_LINE            01            02  \\\n",
            "32         KE  KE01000006      KES  M623100  0.000000e+00  0.000000e+00   \n",
            "132        KE  KE01000020      KES  M623100  0.000000e+00  0.000000e+00   \n",
            "142        KE  KE01000022      KES  M623100  0.000000e+00  0.000000e+00   \n",
            "177        KE  KE01000028      KES  M623100  0.000000e+00  0.000000e+00   \n",
            "246        KE  KE01000041      KES  M623100  0.000000e+00  0.000000e+00   \n",
            "...       ...         ...      ...      ...           ...           ...   \n",
            "18873      KE  KE01008132      KES  M623100 -3.476751e+06 -3.762851e+06   \n",
            "18874      KE  KE01008138      KES  M623100  0.000000e+00 -1.142830e+06   \n",
            "18875      KE  KE01008150      KES  M623100 -7.084999e+05 -7.085887e+05   \n",
            "18876      KE  KE01008200      KES  M623100 -1.758707e+06 -1.758707e+06   \n",
            "18877      KE  KE01008202      KES  M623100  0.000000e+00 -3.550000e+05   \n",
            "\n",
            "              03         04            05            06  ...            08  \\\n",
            "32           0.0        0.0 -1.863537e+06 -1.566862e+06  ... -1.328429e+06   \n",
            "132          0.0        0.0 -1.010543e+06 -1.010249e+06  ... -1.005825e+06   \n",
            "142          0.0        0.0 -9.919659e+05 -9.878944e+05  ... -9.440161e+05   \n",
            "177          0.0        0.0 -1.070703e+06 -1.070703e+06  ... -1.070703e+06   \n",
            "246          0.0        0.0 -5.320390e+05 -5.322890e+05  ... -6.697410e+05   \n",
            "...          ...        ...           ...           ...  ...           ...   \n",
            "18873 -3953834.0 -4487545.9 -3.309912e+06 -3.309912e+06  ... -3.309912e+06   \n",
            "18874 -1142829.8 -1097232.8 -9.994308e+05 -9.994308e+05  ... -9.106928e+05   \n",
            "18875  -707852.0  -807472.0 -7.282570e+05 -7.285574e+05  ... -7.285574e+05   \n",
            "18876 -1758707.0 -2809864.0 -2.021496e+06 -2.134389e+06  ... -1.962483e+06   \n",
            "18877  -355000.0  -355000.0 -3.550000e+05 -3.560788e+05  ... -3.550000e+05   \n",
            "\n",
            "                 09          10          11            12  Year  \\\n",
            "32    -1.369822e+06 -1340000.00 -1340320.00 -1.519096e+06  2019   \n",
            "132   -1.026825e+06 -1050825.00 -1050825.00 -1.050825e+06  2019   \n",
            "142   -9.553954e+05  -944901.03  -945069.67 -9.470784e+05  2019   \n",
            "177   -1.070703e+06 -1070703.00 -1070703.00 -1.071172e+06  2019   \n",
            "246   -6.705472e+05  -667711.00  -668711.00 -6.677110e+05  2019   \n",
            "...             ...         ...         ...           ...   ...   \n",
            "18873 -3.309912e+06 -3620443.00 -3620443.00 -3.661757e+06  2021   \n",
            "18874 -9.115213e+05  -910692.80 -1370968.05 -1.285238e+06  2021   \n",
            "18875 -7.285574e+05  -728557.40  -728557.40 -7.285574e+05  2021   \n",
            "18876 -1.961434e+06 -1961434.00 -1961434.00 -1.961434e+06  2021   \n",
            "18877 -3.550000e+05  -355000.00  1490000.00 -3.550000e+05  2021   \n",
            "\n",
            "       MRL_Category_Cat1  MRL_Category_Cat2  MRL_Category_Cat3  \\\n",
            "32                     1                  0                  0   \n",
            "132                    1                  0                  0   \n",
            "142                    1                  0                  0   \n",
            "177                    1                  0                  0   \n",
            "246                    1                  0                  0   \n",
            "...                  ...                ...                ...   \n",
            "18873                  1                  0                  0   \n",
            "18874                  1                  0                  0   \n",
            "18875                  1                  0                  0   \n",
            "18876                  1                  0                  0   \n",
            "18877                  1                  0                  0   \n",
            "\n",
            "       MRL_Category_Cat4  \n",
            "32                     0  \n",
            "132                    0  \n",
            "142                    0  \n",
            "177                    0  \n",
            "246                    0  \n",
            "...                  ...  \n",
            "18873                  0  \n",
            "18874                  0  \n",
            "18875                  0  \n",
            "18876                  0  \n",
            "18877                  0  \n",
            "\n",
            "[339 rows x 21 columns]\n",
            "Processing Year: 2019\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_397 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating sequences...\n",
            "1332 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1309, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_398\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_397 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_397 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.2097 - accuracy: 9.5511e-04 - val_loss: 0.1722 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 11s 335ms/step - loss: 0.1540 - accuracy: 9.5511e-04 - val_loss: 0.1233 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 12s 369ms/step - loss: 0.1094 - accuracy: 9.5511e-04 - val_loss: 0.0850 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 11s 332ms/step - loss: 0.0747 - accuracy: 9.5511e-04 - val_loss: 0.0559 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 12s 368ms/step - loss: 0.0488 - accuracy: 9.5511e-04 - val_loss: 0.0348 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 11s 337ms/step - loss: 0.0303 - accuracy: 9.5511e-04 - val_loss: 0.0203 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 11s 330ms/step - loss: 0.0180 - accuracy: 9.5511e-04 - val_loss: 0.0111 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.0102 - accuracy: 9.5511e-04 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.0058 - accuracy: 9.5511e-04 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 12s 369ms/step - loss: 0.0034 - accuracy: 9.5511e-04 - val_loss: 0.0015 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.0022 - accuracy: 9.5511e-04 - val_loss: 8.9783e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 11s 338ms/step - loss: 0.0017 - accuracy: 9.5511e-04 - val_loss: 6.8886e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 9.5511e-04 - val_loss: 6.3837e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 11s 335ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.3919e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 11s 335ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.5295e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.6420e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 11s 334ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.7036e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 11s 332ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.7553e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 11s 341ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.8097e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 11s 336ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.7950e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 12s 374ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.8002e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 13s 389ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.7978e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 11s 334ms/step - loss: 0.0014 - accuracy: 9.5511e-04 - val_loss: 6.8135e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2020\n",
            "Printing X_train and X_test...\n",
            "[-1373361.   -1438744.33 -1408552.67 ...        0.          0.\n",
            "   -61564.2 ]\n",
            "[     0.   -14815.58  -7407.79  -7407.79  -7407.79  -7407.79  -7407.79\n",
            "  -7407.79  -7407.79  -7407.79  -7407.79  -7407.79]\n",
            "Creating sequences...\n",
            "1332 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1309, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_398 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_399\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_398 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_398 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "33/33 [==============================] - 11s 334ms/step - loss: 0.2178 - accuracy: 9.5511e-04 - val_loss: 0.1844 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 11s 334ms/step - loss: 0.1608 - accuracy: 9.5511e-04 - val_loss: 0.1335 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 11s 342ms/step - loss: 0.1149 - accuracy: 9.5511e-04 - val_loss: 0.0932 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 11s 339ms/step - loss: 0.0791 - accuracy: 9.5511e-04 - val_loss: 0.0624 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 12s 373ms/step - loss: 0.0521 - accuracy: 9.5511e-04 - val_loss: 0.0396 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 0.0327 - accuracy: 9.5511e-04 - val_loss: 0.0238 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 12s 372ms/step - loss: 0.0194 - accuracy: 9.5511e-04 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 11s 333ms/step - loss: 0.0110 - accuracy: 9.5511e-04 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 11s 333ms/step - loss: 0.0060 - accuracy: 9.5511e-04 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 0.0033 - accuracy: 9.5511e-04 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 11s 337ms/step - loss: 0.0019 - accuracy: 9.5511e-04 - val_loss: 7.0697e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 0.0013 - accuracy: 9.5511e-04 - val_loss: 3.2487e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 11s 335ms/step - loss: 9.7904e-04 - accuracy: 9.5511e-04 - val_loss: 1.7431e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 11s 347ms/step - loss: 8.6903e-04 - accuracy: 9.5511e-04 - val_loss: 1.1841e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 8.2555e-04 - accuracy: 9.5511e-04 - val_loss: 1.0230e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 12s 373ms/step - loss: 8.1038e-04 - accuracy: 9.5511e-04 - val_loss: 9.8350e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 11s 338ms/step - loss: 8.0476e-04 - accuracy: 0.0029 - val_loss: 9.8076e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 11s 333ms/step - loss: 8.0313e-04 - accuracy: 0.0029 - val_loss: 9.8546e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 8.0258e-04 - accuracy: 0.0029 - val_loss: 9.9245e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 12s 371ms/step - loss: 8.0240e-04 - accuracy: 0.0029 - val_loss: 9.9464e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 11s 339ms/step - loss: 8.0239e-04 - accuracy: 0.0029 - val_loss: 1.0002e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 11s 334ms/step - loss: 8.0241e-04 - accuracy: 0.0029 - val_loss: 9.9276e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 11s 335ms/step - loss: 8.0225e-04 - accuracy: 0.0029 - val_loss: 9.9790e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 12s 370ms/step - loss: 8.0217e-04 - accuracy: 0.0029 - val_loss: 1.0008e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 11s 333ms/step - loss: 8.0216e-04 - accuracy: 0.0029 - val_loss: 9.9491e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 11s 333ms/step - loss: 8.0213e-04 - accuracy: 0.0029 - val_loss: 1.0006e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 12s 369ms/step - loss: 8.0228e-04 - accuracy: 0.0029 - val_loss: 1.0013e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_399 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2021\n",
            "Printing X_train and X_test...\n",
            "[-1268215. -1068393. -1151233. ... -1961434. -1961434. -1961434.]\n",
            "[      0.      -355000.      -355000.      -355000.      -355000.\n",
            " -356078.81593 -355000.      -355000.      -355000.      -355000.\n",
            " 1490000.      -355000.     ]\n",
            "Creating sequences...\n",
            "1368 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1345, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_400\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_399 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_399 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "34/34 [==============================] - 12s 351ms/step - loss: 0.2050 - accuracy: 9.2937e-04 - val_loss: 0.1768 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 12s 367ms/step - loss: 0.1484 - accuracy: 9.2937e-04 - val_loss: 0.1258 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 12s 367ms/step - loss: 0.1036 - accuracy: 9.2937e-04 - val_loss: 0.0860 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 12s 369ms/step - loss: 0.0693 - accuracy: 9.2937e-04 - val_loss: 0.0560 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 12s 354ms/step - loss: 0.0441 - accuracy: 9.2937e-04 - val_loss: 0.0345 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 12s 358ms/step - loss: 0.0267 - accuracy: 9.2937e-04 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 11s 332ms/step - loss: 0.0154 - accuracy: 9.2937e-04 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 12s 369ms/step - loss: 0.0086 - accuracy: 9.2937e-04 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 12s 366ms/step - loss: 0.0048 - accuracy: 9.2937e-04 - val_loss: 0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0030 - accuracy: 9.2937e-04 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 12s 365ms/step - loss: 0.0021 - accuracy: 9.2937e-04 - val_loss: 6.6695e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 12s 366ms/step - loss: 0.0017 - accuracy: 9.2937e-04 - val_loss: 3.6133e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 11s 334ms/step - loss: 0.0016 - accuracy: 9.2937e-04 - val_loss: 2.3926e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 12s 369ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.7620e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.4881e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 11s 332ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.3473e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 12s 367ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2932e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 11s 336ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2510e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2337e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 12s 370ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2375e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2795e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 12s 367ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2694e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2136e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 11s 329ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2608e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 12s 366ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2706e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 12s 363ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2568e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 12s 354ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2121e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 11s 339ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2699e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 12s 360ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2693e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 11s 334ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2354e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 12s 364ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 11s 332ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2776e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2108e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 11s 334ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2151e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 13s 377ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2740e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2244e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2854e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 11s 332ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2657e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 11s 334ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.1612e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 12s 370ms/step - loss: 0.0015 - accuracy: 0.0019 - val_loss: 1.2474e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 13s 373ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2781e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 0.0019 - val_loss: 1.2299e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 12s 369ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2630e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 11s 332ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2834e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 11s 336ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2449e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 11s 330ms/step - loss: 0.0015 - accuracy: 0.0019 - val_loss: 1.2318e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 0.0019 - val_loss: 1.2928e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 13s 369ms/step - loss: 0.0015 - accuracy: 9.2937e-04 - val_loss: 1.2144e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 11s 331ms/step - loss: 0.0015 - accuracy: 0.0019 - val_loss: 1.2739e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2022\n",
            "Processing MRL_LINE: M625010\n",
            "      COUNTRY  VISION_OUC CURRENCY MRL_LINE            01            02  \\\n",
            "31         KE  KE01000006      KES  M625010       0.00000       0.00000   \n",
            "57         KE  KE01000010      KES  M625010       0.00000       0.00000   \n",
            "66         KE  KE01000011      KES  M625010       0.00000       0.00000   \n",
            "81         KE  KE01000013      KES  M625010       0.00000       0.00000   \n",
            "137        KE  KE01000021      KES  M625010       0.00000       0.00000   \n",
            "...       ...         ...      ...      ...           ...           ...   \n",
            "18970      KE  KE01000006      KES  M625010 -155500.00000 -181500.06407   \n",
            "18971      KE  KE01000011      KES  M625010 -123500.00000 -123500.00000   \n",
            "18972      KE  KE01000025      KES  M625010 -101000.00000 -101000.00000   \n",
            "18973      KE  KE01008140      KES  M625010 -161647.87703 -161000.00000   \n",
            "18974      KE  KE01008041      KES  M625010       0.00000       0.00000   \n",
            "\n",
            "                 03            04            05            06  ...  \\\n",
            "31          0.00000       0.00000 -194600.00000 -161000.00000  ...   \n",
            "57          0.00000       0.00000 -206507.28452 -206000.00000  ...   \n",
            "66          0.00000       0.00000  -93529.13789 -123500.00000  ...   \n",
            "81          0.00000       0.00000 -350761.73198 -383579.90239  ...   \n",
            "137         0.00000       0.00000  -90535.53527  -81500.00000  ...   \n",
            "...             ...           ...           ...           ...  ...   \n",
            "18970 -182335.17922 -253710.03975 -221868.08933 -259101.19273  ...   \n",
            "18971 -123500.00000 -139500.00000 -137957.04528 -127500.00000  ...   \n",
            "18972 -115000.00000 -125000.00000  -99500.00000 -103229.24908  ...   \n",
            "18973 -161000.00000 -161000.00000 -161000.00000 -161000.00000  ...   \n",
            "18974       0.00000       0.00000       0.00000       0.00000  ...   \n",
            "\n",
            "                 08            09            10            11            12  \\\n",
            "31    -137000.00000 -137000.00000 -134000.00000 -134956.10597 -167662.94000   \n",
            "57    -206000.00000 -206000.00000 -192933.35000 -193500.00000 -199000.00000   \n",
            "66    -123500.00000 -123500.00000 -123500.00000 -123500.00000 -123500.00000   \n",
            "81    -377992.24000 -396264.84000 -384903.54000 -381235.00397 -368568.69000   \n",
            "137    -78500.00000  -78500.00000  -78500.00000  -80000.00000  -78500.00000   \n",
            "...             ...           ...           ...           ...           ...   \n",
            "18970 -206047.48512 -203050.84111 -210006.71636  -59611.16160 -212167.33544   \n",
            "18971 -127500.00000 -127500.00000 -143501.53424 -121500.00000 -121500.00000   \n",
            "18972 -101000.00000  -99500.00000  -99500.00000 -106147.11931  -99500.00000   \n",
            "18973 -161000.00000 -161000.00000 -161000.00000 -161000.00000 -161000.00000   \n",
            "18974       0.00000  -65929.95355       0.00000       0.00000       0.00000   \n",
            "\n",
            "       Year  MRL_Category_Cat1  MRL_Category_Cat2  MRL_Category_Cat3  \\\n",
            "31     2019                  1                  0                  0   \n",
            "57     2019                  1                  0                  0   \n",
            "66     2019                  1                  0                  0   \n",
            "81     2019                  1                  0                  0   \n",
            "137    2019                  1                  0                  0   \n",
            "...     ...                ...                ...                ...   \n",
            "18970  2021                  1                  0                  0   \n",
            "18971  2021                  1                  0                  0   \n",
            "18972  2021                  1                  0                  0   \n",
            "18973  2021                  1                  0                  0   \n",
            "18974  2021                  1                  0                  0   \n",
            "\n",
            "       MRL_Category_Cat4  \n",
            "31                     0  \n",
            "57                     0  \n",
            "66                     0  \n",
            "81                     0  \n",
            "137                    0  \n",
            "...                  ...  \n",
            "18970                  0  \n",
            "18971                  0  \n",
            "18972                  0  \n",
            "18973                  0  \n",
            "18974                  0  \n",
            "\n",
            "[294 rows x 21 columns]\n",
            "Processing Year: 2019\n",
            "Creating sequences...\n",
            "1176 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1153, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_400 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_401\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_400 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_400 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.2072 - accuracy: 0.0011 - val_loss: 0.1812 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 10s 334ms/step - loss: 0.1578 - accuracy: 0.0011 - val_loss: 0.1360 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 10s 335ms/step - loss: 0.1173 - accuracy: 0.0011 - val_loss: 0.0993 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0847 - accuracy: 0.0011 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 0.0592 - accuracy: 0.0011 - val_loss: 0.0479 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 0.0401 - accuracy: 0.0011 - val_loss: 0.0313 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 11s 382ms/step - loss: 0.0262 - accuracy: 0.0011 - val_loss: 0.0195 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 9s 326ms/step - loss: 0.0167 - accuracy: 0.0011 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0105 - accuracy: 0.0011 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 0.0067 - accuracy: 0.0011 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0045 - accuracy: 0.0011 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0033 - accuracy: 0.0011 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0027 - accuracy: 0.0011 - val_loss: 6.2783e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0024 - accuracy: 0.0011 - val_loss: 3.9482e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0023 - accuracy: 0.0011 - val_loss: 2.8871e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0023 - accuracy: 0.0011 - val_loss: 2.4025e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 10s 351ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 2.1704e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 10s 351ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 2.0410e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 10s 342ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9645e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 10s 341ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9462e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 10s 335ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9197e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 9s 329ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.8839e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9226e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9053e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9186e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.8889e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 10s 334ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9397e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 10s 341ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9071e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 11s 373ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.8995e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.8879e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 10s 329ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.9168e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 0.0022 - accuracy: 0.0011 - val_loss: 1.8961e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_401 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2020\n",
            "Printing X_train and X_test...\n",
            "[-99481.52922 -74575.      -79575.      ... -68000.      -68000.\n",
            " -68000.     ]\n",
            "[    0.          0.      -1101.91425     0.          0.          0.\n",
            "     0.          0.          0.          0.          0.          0.     ]\n",
            "Creating sequences...\n",
            "1164 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1141, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_402\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_401 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_401 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.2264 - accuracy: 0.0011 - val_loss: 0.1950 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 10s 332ms/step - loss: 0.1741 - accuracy: 0.0011 - val_loss: 0.1477 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 10s 334ms/step - loss: 0.1308 - accuracy: 0.0011 - val_loss: 0.1089 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 9s 329ms/step - loss: 0.0955 - accuracy: 0.0011 - val_loss: 0.0779 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 0.0675 - accuracy: 0.0011 - val_loss: 0.0537 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 10s 343ms/step - loss: 0.0461 - accuracy: 0.0011 - val_loss: 0.0355 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0302 - accuracy: 0.0011 - val_loss: 0.0224 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0190 - accuracy: 0.0011 - val_loss: 0.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0115 - accuracy: 0.0011 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 10s 335ms/step - loss: 0.0068 - accuracy: 0.0011 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0039 - accuracy: 0.0011 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 9s 327ms/step - loss: 0.0023 - accuracy: 0.0011 - val_loss: 0.0010 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0015 - accuracy: 0.0011 - val_loss: 4.6295e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 10s 341ms/step - loss: 0.0011 - accuracy: 0.0011 - val_loss: 2.1945e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 8.8689e-04 - accuracy: 0.0022 - val_loss: 1.1172e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 7.9822e-04 - accuracy: 0.0022 - val_loss: 7.0624e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 7.6110e-04 - accuracy: 0.0022 - val_loss: 5.7436e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 7.4641e-04 - accuracy: 0.0022 - val_loss: 5.4717e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 11s 369ms/step - loss: 7.4097e-04 - accuracy: 0.0011 - val_loss: 5.5174e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 9s 326ms/step - loss: 7.3887e-04 - accuracy: 0.0011 - val_loss: 5.6292e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 10s 331ms/step - loss: 7.3824e-04 - accuracy: 0.0011 - val_loss: 5.7210e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 10s 343ms/step - loss: 7.3794e-04 - accuracy: 0.0011 - val_loss: 5.7826e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 10s 335ms/step - loss: 7.3787e-04 - accuracy: 0.0011 - val_loss: 5.7732e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 10s 341ms/step - loss: 7.3806e-04 - accuracy: 0.0011 - val_loss: 5.8236e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 10s 338ms/step - loss: 7.3795e-04 - accuracy: 0.0011 - val_loss: 5.7689e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 7.3777e-04 - accuracy: 0.0011 - val_loss: 5.8580e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 9s 322ms/step - loss: 7.3767e-04 - accuracy: 0.0011 - val_loss: 5.8376e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 10s 347ms/step - loss: 7.3783e-04 - accuracy: 0.0011 - val_loss: 5.8557e-05 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2021\n",
            "Printing X_train and X_test...\n",
            "[-730020.7 -730020.7 -730020.7 ... -161000.  -161000.  -161000. ]\n",
            "[     0.           0.           0.           0.           0.\n",
            "      0.           0.           0.      -65929.95355      0.\n",
            "      0.           0.     ]\n",
            "Creating sequences...\n",
            "1152 12\n",
            "Printing X_train and X_test... reshape\n",
            "(1129, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_402 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_403\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_402 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_402 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "29/29 [==============================] - 10s 345ms/step - loss: 0.2209 - accuracy: 0.0011 - val_loss: 0.1873 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 10s 331ms/step - loss: 0.1696 - accuracy: 0.0011 - val_loss: 0.1411 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 9s 318ms/step - loss: 0.1270 - accuracy: 0.0011 - val_loss: 0.1034 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0924 - accuracy: 0.0011 - val_loss: 0.0732 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 10s 332ms/step - loss: 0.0651 - accuracy: 0.0011 - val_loss: 0.0498 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 10s 334ms/step - loss: 0.0443 - accuracy: 0.0011 - val_loss: 0.0324 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 10s 338ms/step - loss: 0.0290 - accuracy: 0.0011 - val_loss: 0.0201 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 10s 336ms/step - loss: 0.0184 - accuracy: 0.0011 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 0.0113 - accuracy: 0.0011 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 9s 323ms/step - loss: 0.0070 - accuracy: 0.0011 - val_loss: 0.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 10s 330ms/step - loss: 0.0044 - accuracy: 0.0011 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 10s 332ms/step - loss: 0.0030 - accuracy: 0.0011 - val_loss: 7.8125e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 10s 333ms/step - loss: 0.0023 - accuracy: 0.0011 - val_loss: 3.6543e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0019 - accuracy: 0.0011 - val_loss: 1.8820e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 10s 342ms/step - loss: 0.0018 - accuracy: 0.0011 - val_loss: 1.2604e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 11s 388ms/step - loss: 0.0017 - accuracy: 0.0022 - val_loss: 1.0736e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 0.0017 - accuracy: 0.0022 - val_loss: 1.0581e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 11s 370ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.0919e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 9s 322ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1280e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 10s 337ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1522e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 10s 346ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1563e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 10s 340ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1895e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 10s 339ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1930e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 10s 338ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1988e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 11s 372ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1837e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 10s 335ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1819e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 9s 323ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 1.1808e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2022\n",
            "Processing MRL_LINE: M625020\n",
            "      COUNTRY  VISION_OUC CURRENCY MRL_LINE         01            02  \\\n",
            "811        KE  KE01000009      KES  M625020       0.00       0.00000   \n",
            "816        KE  KE01000022      KES  M625020       0.00       0.00000   \n",
            "822        KE  KE01000035      KES  M625020       0.00       0.00000   \n",
            "999        KE  KE01000020      KES  M625020       0.00       0.00000   \n",
            "1011       KE  KE01000029      KES  M625020       0.00       0.00000   \n",
            "...       ...         ...      ...      ...        ...           ...   \n",
            "19021      KE  KE01000029      KES  M625020  -73294.85  -75457.13833   \n",
            "19022      KE  KE01000030      KES  M625020 -258353.08 -258353.08000   \n",
            "19023      KE  KE01000025      KES  M625020  -57798.94  -57798.94000   \n",
            "19024      KE  KE01000027      KES  M625020  -65253.45  -65253.45000   \n",
            "19025      KE  KE0100PC07      KES  M625020       0.00       0.00000   \n",
            "\n",
            "              03         04           05            06  ...         08  \\\n",
            "811         0.00       0.00     -1427.50 -1.880994e+03  ...   -1082.50   \n",
            "816         0.00       0.00         0.00 -5.579810e+02  ...       0.00   \n",
            "822         0.00       0.00     87940.00  7.894392e+04  ...   93290.00   \n",
            "999         0.00       0.00         0.00  0.000000e+00  ...       0.00   \n",
            "1011        0.00       0.00         0.00  0.000000e+00  ...       0.00   \n",
            "...          ...        ...          ...           ...  ...        ...   \n",
            "19021  -76294.85  -73294.85   -246149.33 -4.715930e+05  ... -532443.77   \n",
            "19022 -258353.08 -258353.08   -426923.66 -6.558079e+05  ... -714555.41   \n",
            "19023  -57798.94  -57798.94   -192925.85 -3.718894e+05  ... -419875.12   \n",
            "19024  -65253.45  -65253.45   -217808.11 -4.198531e+05  ... -474027.74   \n",
            "19025       0.00       0.00 -20000000.00  2.000000e+07  ...       0.00   \n",
            "\n",
            "                 09            10            11         12  Year  \\\n",
            "811     -1415.00000   -1522.50000   -1340.00000   -2850.00  2019   \n",
            "816         0.00000    1399.43000       0.00000       0.00  2019   \n",
            "822     98820.00000  105310.00000   91130.19789  117780.00  2019   \n",
            "999         0.00000       0.00000   -2812.82473       0.00  2019   \n",
            "1011    -6949.31581       0.00000       0.00000       0.00  2019   \n",
            "...             ...           ...           ...        ...   ...   \n",
            "19021 -571975.47000 -570475.47000 -608507.17000 -646538.87  2021   \n",
            "19022 -751969.23000 -751969.23000 -789383.05000 -826796.87  2021   \n",
            "19023 -449866.20000 -449866.20000 -479857.28000 -509848.36  2021   \n",
            "19024 -507886.86000 -509045.12803 -541745.98000 -575605.10  2021   \n",
            "19025       0.00000       0.00000       0.00000       0.00  2021   \n",
            "\n",
            "       MRL_Category_Cat1  MRL_Category_Cat2  MRL_Category_Cat3  \\\n",
            "811                    0                  0                  1   \n",
            "816                    0                  0                  1   \n",
            "822                    0                  0                  1   \n",
            "999                    0                  0                  1   \n",
            "1011                   0                  0                  1   \n",
            "...                  ...                ...                ...   \n",
            "19021                  0                  0                  1   \n",
            "19022                  0                  0                  1   \n",
            "19023                  0                  0                  1   \n",
            "19024                  0                  0                  1   \n",
            "19025                  0                  0                  1   \n",
            "\n",
            "       MRL_Category_Cat4  \n",
            "811                    0  \n",
            "816                    0  \n",
            "822                    0  \n",
            "999                    0  \n",
            "1011                   0  \n",
            "...                  ...  \n",
            "19021                  0  \n",
            "19022                  0  \n",
            "19023                  0  \n",
            "19024                  0  \n",
            "19025                  0  \n",
            "\n",
            "[152 rows x 21 columns]\n",
            "Processing Year: 2019\n",
            "Creating sequences...\n",
            "588 12\n",
            "Printing X_train and X_test... reshape\n",
            "(565, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_403 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_404\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_403 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_403 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15/15 [==============================] - 5s 324ms/step - loss: 0.2394 - accuracy: 0.0022 - val_loss: 0.2229 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.2103 - accuracy: 0.0022 - val_loss: 0.1951 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 5s 344ms/step - loss: 0.1836 - accuracy: 0.0022 - val_loss: 0.1696 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.1593 - accuracy: 0.0022 - val_loss: 0.1466 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.1373 - accuracy: 0.0022 - val_loss: 0.1258 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 5s 371ms/step - loss: 0.1175 - accuracy: 0.0022 - val_loss: 0.1068 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0997 - accuracy: 0.0022 - val_loss: 0.0902 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.0840 - accuracy: 0.0022 - val_loss: 0.0756 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 6s 413ms/step - loss: 0.0702 - accuracy: 0.0022 - val_loss: 0.0627 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0582 - accuracy: 0.0022 - val_loss: 0.0515 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 5s 369ms/step - loss: 0.0477 - accuracy: 0.0022 - val_loss: 0.0418 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0388 - accuracy: 0.0022 - val_loss: 0.0336 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0312 - accuracy: 0.0022 - val_loss: 0.0266 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0248 - accuracy: 0.0022 - val_loss: 0.0209 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0196 - accuracy: 0.0022 - val_loss: 0.0161 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0153 - accuracy: 0.0022 - val_loss: 0.0123 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0119 - accuracy: 0.0022 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0092 - accuracy: 0.0022 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0071 - accuracy: 0.0022 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 6s 378ms/step - loss: 0.0056 - accuracy: 0.0022 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0044 - accuracy: 0.0022 - val_loss: 0.0027 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0035 - accuracy: 0.0022 - val_loss: 0.0019 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0028 - accuracy: 0.0022 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.0023 - accuracy: 0.0022 - val_loss: 9.1827e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0020 - accuracy: 0.0022 - val_loss: 6.2776e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 5s 341ms/step - loss: 0.0018 - accuracy: 0.0022 - val_loss: 4.2759e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0016 - accuracy: 0.0022 - val_loss: 2.9025e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0015 - accuracy: 0.0022 - val_loss: 1.9332e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0014 - accuracy: 0.0022 - val_loss: 1.2548e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0014 - accuracy: 0.0022 - val_loss: 6.7028e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0013 - accuracy: 0.0022 - val_loss: 4.0586e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.7093e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.2305e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.6727e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.1388e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 5s 357ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.8140e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.7956e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 5s 358ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.2119e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 5s 329ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.5016e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 6s 376ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.4953e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.9412e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 5s 328ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.0032e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.7533e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.7028e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 1.7927e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.4649e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 5s 368ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.2524e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.0013 - accuracy: 0.0044 - val_loss: 2.1467e-06 - val_accuracy: 0.0000e+00\n",
            "Processing Year: 2020\n",
            "Printing X_train and X_test...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_404 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2.69926390e+05 -2.69926390e+05 -2.69926390e+05 -2.69926390e+05\n",
            " -8.09779170e+05  2.69926390e+05 -2.70306213e+05 -2.69926390e+05\n",
            " -2.69926390e+05 -2.69926390e+05 -2.69926390e+05 -2.69926390e+05\n",
            " -1.06643780e+05 -1.06643780e+05 -1.06643780e+05 -1.06643780e+05\n",
            " -3.19931340e+05  1.06643780e+05 -1.06643780e+05 -1.06643780e+05\n",
            " -1.06643780e+05 -1.06643780e+05 -1.06643780e+05 -1.08083692e+05\n",
            " -4.55523000e+04 -3.55523000e+04 -3.55523000e+04 -4.05523000e+04\n",
            " -1.06656900e+05  2.05523000e+04 -4.05523000e+04 -4.05523000e+04\n",
            " -3.55523000e+04 -3.55523000e+04 -4.05523000e+04 -3.55523000e+04\n",
            " -8.69050800e+04 -8.69050800e+04 -8.69050800e+04 -8.69050800e+04\n",
            " -2.60715240e+05  8.69050800e+04 -8.69050800e+04 -8.69050800e+04\n",
            " -8.71425800e+04 -8.69050800e+04 -8.75044562e+04 -8.69050800e+04\n",
            " -8.47792400e+04 -8.47792400e+04 -8.47792400e+04 -8.47792400e+04\n",
            " -2.54337720e+05  8.47792400e+04 -8.47792400e+04 -8.55127805e+04\n",
            " -8.47792400e+04 -8.47792400e+04 -8.47792400e+04 -8.47792400e+04\n",
            " -9.81701400e+04 -9.81701400e+04 -9.81701400e+04 -9.81701400e+04\n",
            " -2.95620859e+05  9.81701400e+04 -9.81701400e+04 -9.81701400e+04\n",
            " -9.81701400e+04 -9.90284752e+04 -9.81701400e+04 -9.81701400e+04\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -9.32110200e+04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.11286000e+03\n",
            "  4.10000000e-01  4.30000000e-01  0.00000000e+00 -8.00000000e-01\n",
            " -2.30025400e+05 -2.30025400e+05 -2.30025400e+05 -2.30025400e+05\n",
            " -6.90076200e+05  2.30025400e+05 -2.30025400e+05 -2.26008038e+05\n",
            " -2.30025400e+05 -2.30025400e+05 -2.30025400e+05 -2.30025400e+05\n",
            " -1.33041221e+05 -1.32797250e+05 -1.32797250e+05 -1.32797250e+05\n",
            " -3.98391750e+05  1.32797250e+05 -1.32797250e+05 -1.32797250e+05\n",
            " -1.32797250e+05 -1.32797250e+05 -1.32797250e+05 -1.32797250e+05\n",
            " -1.15898030e+05 -1.15898030e+05 -1.35199331e+05 -1.15898030e+05\n",
            " -3.54881808e+05  1.15898030e+05 -1.15898030e+05 -1.15898030e+05\n",
            " -1.15898030e+05 -1.15898030e+05 -1.15898030e+05 -1.15898030e+05\n",
            " -8.14807000e+04 -8.14807000e+04 -8.14807000e+04 -8.14807000e+04\n",
            " -2.44442100e+05  8.14807000e+04 -8.14807000e+04 -8.14807000e+04\n",
            " -8.30209600e+04 -8.14807000e+04 -8.14807000e+04 -8.14807000e+04\n",
            " -8.15327144e+06 -8.15327144e+06 -8.15327144e+06 -8.15327144e+06\n",
            "  7.53933691e+06  8.15327144e+06 -8.15327144e+06 -8.15327144e+06\n",
            " -8.15327144e+06 -8.15327144e+06 -8.15327144e+06 -8.15327144e+06\n",
            " -9.50066500e+04 -9.63552658e+04 -9.55231967e+04 -9.77292344e+04\n",
            " -2.85019950e+05  9.32083714e+04 -9.50066500e+04 -9.50066500e+04\n",
            " -9.50066500e+04 -9.50066500e+04 -9.50066500e+04 -9.50066500e+04\n",
            " -1.05105780e+05 -1.05573351e+05 -1.05105780e+05 -1.05105780e+05\n",
            " -3.15317340e+05  1.05105780e+05 -1.05105780e+05 -1.05105780e+05\n",
            " -1.05105780e+05 -1.05105780e+05 -1.05105780e+05 -1.05105780e+05\n",
            " -1.37762890e+05 -1.36155380e+05 -1.87180886e+06  2.79274430e+05\n",
            " -3.97472450e+05  1.01632810e+05 -1.63673430e+05 -1.63773490e+05\n",
            " -1.63773490e+05 -1.63773490e+05 -1.63773490e+05 -1.63773490e+05\n",
            "  2.08982905e+07 -8.14059719e+06  2.05546110e+07  2.01727233e+07\n",
            "  1.95904109e+07  1.90395959e+07  1.58906554e+07  2.86009383e+07\n",
            "  1.35011742e+07  1.54832359e+07  1.35782486e+07  1.20142664e+07\n",
            " -1.25430610e+05 -1.25430610e+05 -1.25430610e+05 -1.25430610e+05\n",
            " -3.76291830e+05  1.24323192e+05 -1.25430610e+05 -1.26570502e+05\n",
            " -1.25430610e+05 -1.25430610e+05 -1.25430610e+05 -1.25430610e+05\n",
            " -1.01526190e+05 -1.01376190e+05 -1.01076190e+05 -1.03036071e+05\n",
            " -3.01728570e+05  1.00176190e+05 -1.03068176e+05 -1.00176190e+05\n",
            " -1.00476190e+05 -1.00626190e+05 -1.01026190e+05 -1.01376190e+05\n",
            " -8.09020700e+04 -8.09020700e+04 -8.30983707e+04 -8.09020700e+04\n",
            " -2.42706210e+05  8.09020700e+04 -8.09020700e+04 -8.22923168e+04\n",
            " -8.09020700e+04 -8.09020700e+04 -8.27379333e+04 -8.09020700e+04\n",
            " -6.65673100e+04 -6.65673100e+04 -6.65673100e+04 -8.00351311e+04\n",
            " -1.99701930e+05  6.65673100e+04 -6.65673100e+04 -6.65673100e+04\n",
            " -6.65673100e+04 -6.65673100e+04 -6.65673100e+04 -6.65673100e+04\n",
            " -9.46072900e+04 -9.46072900e+04 -9.46072900e+04 -9.46072900e+04\n",
            " -2.83821870e+05  9.46072900e+04 -9.46072900e+04 -9.46072900e+04\n",
            " -9.49577685e+04 -9.46072900e+04 -9.46072900e+04 -9.46072900e+04\n",
            " -3.02062860e+05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -3.29716500e+06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00 -5.73221690e+05 -4.55587112e+05 -5.23645360e+05\n",
            " -1.04176800e+06  3.46364844e+06 -4.37642280e+05 -4.80108350e+05\n",
            " -4.37642280e+05 -4.59060280e+05 -4.37642280e+05 -4.91975280e+05\n",
            "  0.00000000e+00  0.00000000e+00 -1.06363315e+03  0.00000000e+00\n",
            " -2.18661097e+03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -5.06422700e+04 -5.06422700e+04 -5.06422700e+04 -5.23122645e+04\n",
            " -1.53337306e+05  5.06422700e+04 -5.17946462e+04 -5.06422700e+04\n",
            " -5.06422700e+04 -5.19186273e+04 -5.31943065e+04 -5.06422700e+04\n",
            " -7.44102600e+04 -7.44102600e+04 -7.44102600e+04 -7.44102600e+04\n",
            " -2.20830780e+05  7.09312928e+04 -7.44102600e+04 -7.44102600e+04\n",
            " -7.42102600e+04 -7.42102600e+04 -7.45046562e+04 -7.42102600e+04\n",
            " -9.08851252e+04 -9.13153000e+04 -9.07153000e+04 -8.71153000e+04\n",
            " -2.57145900e+05  8.29153000e+04 -8.65153000e+04 -8.77153000e+04\n",
            " -8.89153000e+04 -8.95153000e+04 -8.71153000e+04 -9.31153000e+04\n",
            " -8.63597700e+04 -8.71862319e+04 -8.63597700e+04 -8.63597700e+04\n",
            " -2.59079310e+05  8.63597700e+04 -8.63597700e+04 -8.63597700e+04\n",
            " -8.63597700e+04 -8.63597700e+04 -8.63597700e+04 -8.63597700e+04\n",
            " -4.91525400e+04 -4.95329595e+04 -4.98011297e+04 -4.91525400e+04\n",
            " -1.47457620e+05  4.91525400e+04 -4.91525400e+04 -4.91525400e+04\n",
            " -4.91525400e+04 -4.91525400e+04 -4.91525400e+04 -4.91525400e+04\n",
            " -9.65859000e+03 -2.77934230e+05 -1.38967120e+05 -1.38967120e+05\n",
            "  2.88248649e+07 -2.91027991e+07 -1.38967120e+05 -1.38967120e+05\n",
            " -1.38967120e+05 -1.38967120e+05 -1.38967120e+05 -1.38967120e+05\n",
            " -1.69153568e+05 -1.63267720e+05 -1.78959000e+05 -1.63267720e+05\n",
            " -4.89803160e+05  1.63267720e+05 -1.63267720e+05 -1.63267720e+05\n",
            " -1.63267720e+05 -1.63267720e+05 -1.63267720e+05 -1.63267720e+05\n",
            "  0.00000000e+00  0.00000000e+00  6.21406800e+04  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -1.01671373e+05 -1.01911096e+05 -1.00529900e+05 -1.00529900e+05\n",
            " -3.01589700e+05  1.00529900e+05 -1.00529900e+05 -1.00529900e+05\n",
            " -1.00529900e+05 -1.00529900e+05 -1.00529900e+05 -1.00529900e+05\n",
            " -1.37409070e+05 -7.74517700e+04 -1.03843770e+05 -7.74517700e+04\n",
            " -1.36199175e+06  2.08127700e+04 -1.45146455e+05 -8.86237700e+04\n",
            " -1.99790770e+05 -2.00933770e+05 -8.63717700e+04 -1.42857770e+05\n",
            " -1.11114680e+05 -1.12614680e+05 -1.05973246e+05 -1.05114680e+05\n",
            " -2.94344040e+05  7.95241154e+04 -9.76146800e+04 -1.06614680e+05\n",
            " -1.00614680e+05 -1.03614680e+05 -1.00614680e+05 -1.05114680e+05\n",
            " -7.26366400e+04 -7.50486200e+04 -7.44433000e+04 -3.13604800e+04\n",
            " -2.44740372e+05  1.01345430e+05 -6.42693600e+04 -8.65694800e+04\n",
            " -4.81518500e+04 -6.38283200e+04 -5.26644100e+04 -5.23187700e+04\n",
            " -1.15161690e+05 -1.17764584e+05 -1.15161690e+05 -1.15161690e+05\n",
            " -3.45485070e+05  1.15161690e+05 -1.15161690e+05 -1.15161690e+05\n",
            " -1.17894844e+05 -1.15161690e+05 -1.15161690e+05 -1.19515651e+05\n",
            " -5.69093580e+05 -4.88822850e+05 -5.81156564e+05 -6.48155450e+05\n",
            " -1.18847525e+06 -4.84882700e+04 -5.20598540e+05 -5.01953600e+05\n",
            " -3.38677660e+05 -4.92488440e+05 -4.08204830e+05 -4.29708530e+05\n",
            " -1.01722480e+05 -1.08372650e+05 -1.12987300e+05 -1.17581940e+05\n",
            " -3.94263120e+05  1.41089230e+05 -1.34977990e+05 -1.36849274e+05\n",
            " -1.35489110e+05 -1.35489110e+05 -1.35489110e+05 -1.35489110e+05\n",
            " -8.76002100e+04 -8.76002100e+04 -8.76002100e+04 -8.76002100e+04\n",
            " -2.62800630e+05  8.76002100e+04 -8.82987206e+04 -8.76002100e+04\n",
            " -8.76002100e+04 -8.76002100e+04 -8.76002100e+04 -8.76002100e+04\n",
            " -7.10534800e+04 -7.06834800e+04 -7.10534800e+04 -7.12434800e+04\n",
            " -2.12150440e+05  6.87135528e+04 -7.07134800e+04 -7.08734800e+04\n",
            " -7.06234800e+04 -7.08734800e+04 -7.11234800e+04 -7.13034800e+04\n",
            " -7.61063764e+04 -7.35011900e+04 -7.30863200e+04 -7.30863200e+04\n",
            " -2.19258960e+05  7.30863200e+04 -7.44056900e+04 -7.30863200e+04\n",
            " -7.30863200e+04 -7.30863200e+04 -7.31703900e+04 -7.71990800e+04\n",
            " -7.72727590e+04 -7.84602941e+04 -7.74281296e+04 -7.69771100e+04\n",
            " -2.30931330e+05  7.69771100e+04 -7.69771100e+04 -7.69771100e+04\n",
            " -7.69771100e+04 -7.69771100e+04 -7.69771100e+04 -7.69771100e+04\n",
            " -7.23353100e+04 -7.23353100e+04 -7.23353100e+04 -7.23353100e+04\n",
            " -2.17005930e+05  7.23353100e+04 -7.23353100e+04 -7.23353100e+04\n",
            " -7.24262900e+04 -7.23353100e+04 -7.60102924e+04 -7.23353200e+04\n",
            " -4.32585150e+05 -4.19051840e+05 -4.30916900e+05 -4.22390690e+05\n",
            " -1.00754055e+06 -1.40365638e+05 -4.00467370e+05 -6.80212755e+05\n",
            " -3.94363140e+05 -4.10654470e+05 -3.86718270e+05 -3.87986340e+05\n",
            " -1.01150424e+05 -1.00673040e+05 -1.00673040e+05 -1.00673040e+05\n",
            " -3.02019120e+05  1.00673040e+05 -1.00673040e+05 -1.00673040e+05\n",
            " -1.00673040e+05 -1.00673040e+05 -1.00673040e+05 -1.00661440e+05\n",
            " -9.60288000e+04 -9.60288000e+04 -2.23781840e+05 -9.60288000e+04\n",
            " -2.88086400e+05  9.44382354e+04 -9.60288000e+04 -9.60288000e+04\n",
            " -9.60288000e+04 -9.60288000e+04 -9.60288000e+04 -9.60288000e+04\n",
            " -6.92643700e+04 -6.82643700e+04 -6.92643700e+04 -6.92643700e+04\n",
            " -2.05793110e+05  6.62643700e+04 -6.82643700e+04 -7.12643700e+04\n",
            " -7.12643700e+04 -7.01478226e+04 -7.05376200e+04 -6.82643700e+04\n",
            "  0.00000000e+00  0.00000000e+00 -3.10703400e+04  0.00000000e+00\n",
            "  0.00000000e+00  6.21406800e+04  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "[-31070.34 -31070.34      0.      637.     -637.        0.        0.\n",
            "      0.        0.        0.        0.        0.  ]\n",
            "Creating sequences...\n",
            "600 12\n",
            "Printing X_train and X_test... reshape\n",
            "(577, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_405\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_404 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_404 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 5s 333ms/step - loss: 0.2450 - accuracy: 0.0022 - val_loss: 0.2198 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 5s 356ms/step - loss: 0.2157 - accuracy: 0.0022 - val_loss: 0.1922 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.1888 - accuracy: 0.0022 - val_loss: 0.1668 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 6s 388ms/step - loss: 0.1643 - accuracy: 0.0022 - val_loss: 0.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.1421 - accuracy: 0.0022 - val_loss: 0.1233 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 6s 374ms/step - loss: 0.1222 - accuracy: 0.0022 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.1043 - accuracy: 0.0022 - val_loss: 0.0883 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 5s 328ms/step - loss: 0.0885 - accuracy: 0.0022 - val_loss: 0.0738 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 5s 360ms/step - loss: 0.0745 - accuracy: 0.0022 - val_loss: 0.0610 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 5s 334ms/step - loss: 0.0622 - accuracy: 0.0022 - val_loss: 0.0499 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.0516 - accuracy: 0.0022 - val_loss: 0.0404 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 5s 328ms/step - loss: 0.0425 - accuracy: 0.0022 - val_loss: 0.0323 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0347 - accuracy: 0.0022 - val_loss: 0.0254 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 5s 341ms/step - loss: 0.0283 - accuracy: 0.0022 - val_loss: 0.0197 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0229 - accuracy: 0.0022 - val_loss: 0.0151 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0184 - accuracy: 0.0022 - val_loss: 0.0114 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 5s 328ms/step - loss: 0.0149 - accuracy: 0.0022 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 5s 343ms/step - loss: 0.0121 - accuracy: 0.0022 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0100 - accuracy: 0.0022 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0084 - accuracy: 0.0022 - val_loss: 0.0030 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0071 - accuracy: 0.0022 - val_loss: 0.0021 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0062 - accuracy: 0.0022 - val_loss: 0.0014 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0055 - accuracy: 0.0022 - val_loss: 9.3243e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 6s 378ms/step - loss: 0.0051 - accuracy: 0.0022 - val_loss: 5.9134e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0047 - accuracy: 0.0022 - val_loss: 3.6843e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.0045 - accuracy: 0.0022 - val_loss: 2.2239e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0043 - accuracy: 0.0022 - val_loss: 1.2783e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 5s 331ms/step - loss: 0.0042 - accuracy: 0.0022 - val_loss: 6.8365e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 5s 367ms/step - loss: 0.0041 - accuracy: 0.0043 - val_loss: 3.5304e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0041 - accuracy: 0.0043 - val_loss: 1.7581e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 6s 402ms/step - loss: 0.0041 - accuracy: 0.0043 - val_loss: 9.5293e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 6.5982e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 6s 398ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 7.0202e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 9.4859e-06 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 6s 397ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 1.1074e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 1.4349e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 5s 349ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 1.6138e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 1.7836e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 2.1176e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 2.1959e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 2.4009e-05 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 6s 383ms/step - loss: 0.0040 - accuracy: 0.0043 - val_loss: 2.5457e-05 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_405 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2021\n",
            "Printing X_train and X_test...\n",
            "[-3.27461460e+05 -1.77055200e+05 -2.01280950e+05 -3.88448398e+05\n",
            " -1.36149280e+06 -1.60287041e+06 -1.60457375e+06 -1.58207101e+06\n",
            " -1.44416423e+06 -1.25162119e+06 -1.47408781e+06 -1.79051932e+06\n",
            " -2.86662000e+03 -9.02662000e+03 -7.30662000e+03 -1.30666200e+04\n",
            " -1.23189820e+05 -1.91904220e+05 -2.48419599e+05 -2.46384760e+05\n",
            " -2.71615100e+05 -2.67506300e+05 -2.87565440e+05 -3.06755780e+05\n",
            " -8.18673400e+04 -8.21689500e+04 -8.19856200e+04 -8.15002600e+04\n",
            " -2.55367760e+05 -4.83686815e+05 -5.43984570e+05 -5.44337760e+05\n",
            " -5.82337220e+05 -5.82469150e+05 -6.22487237e+05 -6.58974370e+05\n",
            " -2.00000000e+03 -2.00000000e+03 -2.00000000e+03 -2.00000000e+03\n",
            " -2.00000000e+03 -2.20000000e+03 -2.20000000e+03 -2.20000000e+03\n",
            " -2.20000000e+03 -2.40000000e+03 -2.40000000e+03 -2.40000000e+03\n",
            " -1.22970770e+05 -1.22970770e+05 -1.22970770e+05 -1.22970770e+05\n",
            " -4.10461520e+05 -7.91217370e+05 -8.93423837e+05 -8.93309930e+05\n",
            " -9.57117790e+05 -9.57117790e+05 -1.02116800e+06 -1.08473351e+06\n",
            " -1.26868470e+05 -1.26868470e+05 -1.26868470e+05 -1.26868470e+05\n",
            " -4.23471570e+05 -8.16295910e+05 -9.23038884e+05 -9.21624410e+05\n",
            " -9.87454730e+05 -9.87454730e+05 -1.05328505e+06 -1.11911537e+06\n",
            " -9.41806800e+04 -9.41806800e+04 -1.74264960e+05 -9.41806800e+04\n",
            " -4.30162330e+05 -7.77735630e+05 -8.78088620e+05 -8.78088620e+05\n",
            " -9.40809240e+05 -9.40809240e+05 -1.00422872e+06 -1.06783667e+06\n",
            " -7.54837600e+04 -7.62205035e+04 -7.54837600e+04 -7.54837600e+04\n",
            " -2.51955650e+05 -4.85676920e+05 -5.48344910e+05 -5.48344910e+05\n",
            " -5.87512400e+05 -5.87512400e+05 -6.26679890e+05 -6.65847380e+05\n",
            " -1.49390568e+07 -1.49381068e+07 -5.38635857e+07 -1.49815708e+07\n",
            " -2.93394328e+07 -5.95584022e+07 -4.46409611e+07 -4.46409611e+07\n",
            " -4.78175605e+07 -4.78391141e+07 -5.10152098e+07 -5.41918092e+07\n",
            " -6.20417841e+04 -6.22195169e+04 -6.07460300e+04  1.95099700e+04\n",
            " -2.02762880e+05 -3.90851530e+05 -4.41283990e+05 -4.41283990e+05\n",
            " -4.72804280e+05 -4.72804280e+05 -5.04324570e+05 -5.35844860e+05\n",
            " -1.01810790e+05 -5.81553500e+04 -5.81553500e+04 -1.02361110e+05\n",
            " -2.30824860e+05 -3.74182630e+05 -4.66245400e+05 -4.96022940e+05\n",
            " -4.57268783e+05 -5.36660960e+05 -5.19525640e+05 -5.23794320e+05\n",
            " -4.13114870e+05 -3.85332460e+05 -4.87766840e+05 -5.83588570e+05\n",
            " -6.89522380e+05 -8.21517530e+05 -9.07665960e+05 -8.43700770e+05\n",
            " -8.08615087e+05 -8.11630930e+05 -8.47267290e+05 -1.31191679e+06\n",
            " -2.02676620e+05 -2.02676630e+05 -2.02691140e+05 -2.02676630e+05\n",
            " -6.76560628e+05 -1.30406015e+06 -1.47241812e+06 -1.47232597e+06\n",
            " -1.57749211e+06 -1.57749211e+06 -1.68265825e+06 -1.78782436e+06\n",
            " -7.55912400e+04 -7.55912400e+04 -7.55912400e+04 -7.55912400e+04\n",
            " -2.52314390e+05 -4.86368440e+05 -5.49125660e+05 -5.49125660e+05\n",
            " -5.88348920e+05 -5.88348920e+05 -6.29471357e+05 -6.66795440e+05\n",
            " -6.50014600e+04 -6.50014600e+04 -6.50014600e+04 -6.50014600e+04\n",
            " -2.16967000e+05 -4.18231800e+05 -4.73337312e+05 -4.72197190e+05\n",
            " -5.05925560e+05 -5.05925560e+05 -5.39653930e+05 -5.73382300e+05\n",
            " -6.36572400e+04 -6.36572400e+04 -6.49604560e+04 -6.53666134e+04\n",
            " -2.12480150e+05 -4.09582820e+05 -4.62432220e+05 -4.62432220e+05\n",
            " -4.95463090e+05 -4.95463090e+05 -5.28493960e+05 -5.61524830e+05\n",
            " -8.29683664e+04 -6.40597500e+04 -9.81840100e+04 -8.11218800e+04\n",
            " -2.30885810e+05 -4.12172640e+05 -4.99480470e+05 -4.65356210e+05\n",
            " -4.98595940e+05 -5.16369000e+05 -5.31835670e+05 -6.00621510e+05\n",
            " -6.97177500e+06 -7.14895000e+06 -8.72785489e+06 -8.82811390e+06\n",
            " -8.38512500e+06 -8.97985000e+06 -9.08522500e+06 -9.15725000e+06\n",
            " -9.78550000e+06 -9.15347500e+06 -9.91090000e+06 -8.94132500e+06\n",
            " -8.70230600e+04 -8.70230600e+04 -8.70230600e+04 -8.70230600e+04\n",
            " -2.90472430e+05 -5.59922970e+05 -6.32171100e+05 -6.32171100e+05\n",
            " -6.77326180e+05 -6.77779808e+05 -7.22481260e+05 -7.67636340e+05\n",
            " -7.13365800e+04 -1.79877836e+05 -7.13365800e+04 -7.13365800e+04\n",
            " -2.38112850e+05 -4.58993140e+05 -5.18218060e+05 -5.18218060e+05\n",
            " -5.55233640e+05 -5.55233640e+05 -5.92249220e+05 -6.29264800e+05\n",
            "  0.00000000e+00  0.00000000e+00  2.66947600e+04  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            " -5.43136100e+04 -5.43136100e+04 -5.43136100e+04 -5.43136100e+04\n",
            " -1.81292240e+05 -3.51023660e+05 -3.94556250e+05 -3.94556250e+05\n",
            " -4.22738840e+05 -4.22738840e+05 -4.50921430e+05 -4.79104020e+05\n",
            " -5.49705700e+04 -5.49705700e+04 -5.49705700e+04 -5.49705700e+04\n",
            " -1.84320682e+05 -3.53691150e+05 -3.99328720e+05 -3.99328720e+05\n",
            " -3.81565620e+05 -4.27852200e+05 -4.56375680e+05 -4.69371630e+05\n",
            " -1.01733200e+05 -1.01733200e+05 -1.01914298e+05 -1.02048180e+05\n",
            " -3.39573100e+05 -6.54570820e+05 -7.39229084e+05 -7.39031570e+05\n",
            " -7.91819540e+05 -7.91819540e+05 -8.45083876e+05 -8.97395480e+05\n",
            " -4.99826500e+04 -4.99826500e+04 -4.99826500e+04 -5.16586886e+04\n",
            " -1.66836020e+05 -3.21597890e+05 -3.63094390e+05 -3.63094390e+05\n",
            " -3.89029700e+05 -3.89029700e+05 -4.14965010e+05 -4.40900320e+05\n",
            " -9.16531862e+04 -9.23641177e+04 -8.64701700e+04 -8.64701700e+04\n",
            " -2.88626940e+05 -5.56365550e+05 -6.28154650e+05 -6.28154650e+05\n",
            " -6.73022840e+05 -6.73022840e+05 -7.17891030e+05 -7.62759220e+05\n",
            " -7.10367200e+04 -7.10367200e+04 -7.10367200e+04 -7.10367200e+04\n",
            " -2.37910943e+05 -4.57063800e+05 -5.16039770e+05 -5.16039770e+05\n",
            " -5.52899750e+05 -5.52899750e+05 -5.89759730e+05 -6.26619710e+05\n",
            " -1.27722827e+03 -7.36743470e+02  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -2.78192000e+03 -3.65578000e+03\n",
            " -3.66940000e+03 -3.79171000e+03 -3.58363000e+03 -3.65177000e+03\n",
            " -1.24064937e+05  6.03513050e+05  1.15359924e+06  1.83691238e+06\n",
            "  2.57635954e+06  2.15652902e+06  2.14037105e+06  1.72564986e+06\n",
            "  1.60380473e+06  1.68918340e+06  1.86628995e+06  1.28430243e+06\n",
            " -4.49231303e+04 -4.40721086e+04 -4.29292000e+04 -4.41552000e+04\n",
            " -1.33223500e+05 -2.51661370e+05 -2.82180580e+05 -2.85680580e+05\n",
            " -3.01211340e+05 -3.01561340e+05 -3.20942100e+05 -3.40322860e+05\n",
            " -2.82947600e+04 -2.82947600e+04  2.50947600e+04 -2.80947600e+04\n",
            "  2.52947600e+04 -1.40000000e+03 -1.60000000e+03 -1.60000000e+03\n",
            " -1.40000000e+03 -1.60000000e+03 -1.80000000e+03 -1.80000000e+03\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00 -1.00000000e+03  0.00000000e+00 -4.00000000e+03\n",
            " -4.00000000e+03 -7.00000000e+03 -2.00000000e+03 -2.00000000e+03\n",
            " -2.26806570e+05 -2.26806570e+05 -2.28327181e+05 -2.26806570e+05\n",
            " -7.57052850e+05 -1.45931670e+06 -1.64761563e+06 -1.64761563e+06\n",
            " -1.76530246e+06 -1.76530246e+06 -1.88488847e+06 -1.93390231e+06\n",
            " -6.57753900e+04 -6.57753900e+04 -6.57753900e+04 -6.57753900e+04\n",
            " -2.20385852e+05 -4.23211400e+05 -4.77819320e+05 -4.77819320e+05\n",
            " -5.11949270e+05 -5.11949270e+05 -5.46079220e+05 -5.80209170e+05\n",
            " -7.89196000e+04 -7.89196000e+04 -7.89196000e+04 -7.89196000e+04\n",
            " -2.63424060e+05 -5.08728989e+05 -5.73304250e+05 -5.73304250e+05\n",
            " -6.14254550e+05 -6.14254550e+05 -6.55204820e+05 -6.96155120e+05\n",
            " -5.91805000e+04 -5.72805000e+04 -5.66805000e+04 -5.69805000e+04\n",
            " -2.00013100e+05 -3.89447010e+05 -4.40340170e+05 -4.40040170e+05\n",
            " -4.73985900e+05 -4.74568022e+05 -5.05631630e+05 -5.37077360e+05\n",
            " -5.30282600e+04 -5.30282600e+04 -5.30282600e+04 -5.60282600e+04\n",
            " -1.77001900e+05 -3.62193930e+05 -3.85926187e+05 -3.85218950e+05\n",
            " -4.12734590e+05 -4.18734590e+05 -4.41007019e+05 -4.67765870e+05\n",
            " -5.48775100e+04 -5.56142535e+04 -5.48775100e+04 -5.48775100e+04\n",
            " -1.83174480e+05 -3.53092370e+05 -3.98652680e+05 -3.98652680e+05\n",
            " -4.27127870e+05 -4.27127870e+05 -4.55603060e+05 -4.84078250e+05\n",
            " -1.56710360e+05 -1.33236619e+05 -1.34253371e+05 -1.69540001e+05\n",
            " -4.24083175e+05 -8.08463588e+05 -8.94172325e+05 -8.93403041e+05\n",
            " -9.66469713e+05 -9.69016917e+05 -1.03297596e+06 -1.08805325e+06\n",
            " -7.20000000e+03 -5.20000000e+03 -3.60000000e+03 -6.00000000e+03\n",
            " -3.60000000e+03 -1.08000000e+04 -7.00000000e+03 -5.00000000e+03\n",
            "  0.00000000e+00 -3.80000000e+03 -4.20000000e+03 -1.80000000e+03\n",
            " -1.54206580e+05 -1.54325591e+05 -1.54477158e+05 -1.54329731e+05\n",
            " -5.14722870e+05 -9.92455918e+05 -1.12021963e+06 -1.12032154e+06\n",
            " -1.20034369e+06 -1.20031397e+06 -1.28048229e+06 -1.36026670e+06\n",
            " -8.00744300e+04 -8.00744300e+04 -8.00744300e+04 -8.00744300e+04\n",
            " -2.67278740e+05 -5.15214150e+05 -5.82418285e+05 -5.81693400e+05\n",
            " -6.23242930e+05 -6.23242930e+05 -6.64792460e+05 -7.06341990e+05\n",
            " -7.52181800e+04 -7.52181800e+04 -7.52181800e+04 -7.52181800e+04\n",
            " -2.51069170e+05 -4.83968120e+05 -5.46415620e+05 -5.46415620e+05\n",
            " -5.85445310e+05 -5.85445310e+05 -6.26347925e+05 -6.63504690e+05\n",
            " -6.54578453e+04 -6.48440000e+04 -6.48440000e+04 -6.56098550e+04\n",
            " -2.16441410e+05 -4.17218650e+05 -4.71053310e+05 -4.78579204e+05\n",
            " -5.06109964e+05 -5.04699980e+05 -5.38346650e+05 -5.73765563e+05\n",
            " -2.83684920e+05 -2.51247740e+05 -2.83546000e+05 -3.62704860e+05\n",
            " -7.07569370e+05 -1.22376712e+06 -1.37607033e+06 -1.33464759e+06\n",
            " -1.43328408e+06 -1.45125686e+06 -1.53183382e+06 -1.61985933e+06\n",
            " -7.32948500e+04 -7.54571383e+04 -7.62948500e+04 -7.32948500e+04\n",
            " -2.46149330e+05 -4.71593050e+05 -5.35443770e+05 -5.32443770e+05\n",
            " -5.71975470e+05 -5.70475470e+05 -6.08507170e+05 -6.46538870e+05\n",
            " -2.58353080e+05 -2.58353080e+05 -2.58353080e+05 -2.58353080e+05\n",
            " -4.26923660e+05 -6.55807925e+05 -7.15590249e+05 -7.14555410e+05\n",
            " -7.51969230e+05 -7.51969230e+05 -7.89383050e+05 -8.26796870e+05\n",
            " -5.77989400e+04 -5.77989400e+04 -5.77989400e+04 -5.77989400e+04\n",
            " -1.92925850e+05 -3.71889390e+05 -4.20909959e+05 -4.19875120e+05\n",
            " -4.49866200e+05 -4.49866200e+05 -4.79857280e+05 -5.09848360e+05\n",
            " -6.52534500e+04 -6.52534500e+04 -6.52534500e+04 -6.52534500e+04\n",
            " -2.17808110e+05 -4.19853140e+05 -4.74027740e+05 -4.74027740e+05\n",
            " -5.07886860e+05 -5.09045128e+05 -5.41745980e+05 -5.75605100e+05]\n",
            "[        0.         0.         0.         0. -20000000.  20000000.\n",
            "         0.         0.         0.         0.         0.         0.]\n",
            "Creating sequences...\n",
            "600 12\n",
            "Printing X_train and X_test... reshape\n",
            "(577, 24, 1)\n",
            "(1, 12, 1)\n",
            "Model: \"sequential_406\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_405 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_405 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "15/15 [==============================] - 5s 330ms/step - loss: 0.8663 - accuracy: 0.0022 - val_loss: 0.8547 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 5s 361ms/step - loss: 0.8096 - accuracy: 0.0022 - val_loss: 0.7982 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 5s 343ms/step - loss: 0.7552 - accuracy: 0.0022 - val_loss: 0.7441 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.7033 - accuracy: 0.0022 - val_loss: 0.6922 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 5s 319ms/step - loss: 0.6535 - accuracy: 0.0022 - val_loss: 0.6426 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.6058 - accuracy: 0.0022 - val_loss: 0.5950 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.5602 - accuracy: 0.0022 - val_loss: 0.5493 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.5165 - accuracy: 0.0022 - val_loss: 0.5056 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.4747 - accuracy: 0.0022 - val_loss: 0.4638 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.4347 - accuracy: 0.0022 - val_loss: 0.4237 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.3965 - accuracy: 0.0022 - val_loss: 0.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.3601 - accuracy: 0.0022 - val_loss: 0.3490 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 6s 378ms/step - loss: 0.3257 - accuracy: 0.0022 - val_loss: 0.3147 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.2933 - accuracy: 0.0022 - val_loss: 0.2822 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.2629 - accuracy: 0.0022 - val_loss: 0.2518 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.2344 - accuracy: 0.0022 - val_loss: 0.2237 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.2082 - accuracy: 0.0022 - val_loss: 0.1975 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 5s 354ms/step - loss: 0.1840 - accuracy: 0.0022 - val_loss: 0.1733 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.1617 - accuracy: 0.0022 - val_loss: 0.1513 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.1414 - accuracy: 0.0022 - val_loss: 0.1313 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.1233 - accuracy: 0.0022 - val_loss: 0.1133 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 5s 372ms/step - loss: 0.1070 - accuracy: 0.0022 - val_loss: 0.0971 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0925 - accuracy: 0.0022 - val_loss: 0.0828 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.0797 - accuracy: 0.0022 - val_loss: 0.0702 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 5s 354ms/step - loss: 0.0686 - accuracy: 0.0022 - val_loss: 0.0591 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0589 - accuracy: 0.0022 - val_loss: 0.0496 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 5s 355ms/step - loss: 0.0506 - accuracy: 0.0022 - val_loss: 0.0414 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 5s 325ms/step - loss: 0.0435 - accuracy: 0.0022 - val_loss: 0.0343 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 5s 352ms/step - loss: 0.0375 - accuracy: 0.0022 - val_loss: 0.0283 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0325 - accuracy: 0.0022 - val_loss: 0.0232 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 6s 375ms/step - loss: 0.0283 - accuracy: 0.0022 - val_loss: 0.0190 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0249 - accuracy: 0.0022 - val_loss: 0.0154 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0220 - accuracy: 0.0022 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0198 - accuracy: 0.0022 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0180 - accuracy: 0.0022 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0165 - accuracy: 0.0022 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0153 - accuracy: 0.0022 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 5s 351ms/step - loss: 0.0144 - accuracy: 0.0022 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 5s 327ms/step - loss: 0.0137 - accuracy: 0.0022 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 6s 374ms/step - loss: 0.0131 - accuracy: 0.0022 - val_loss: 0.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0127 - accuracy: 0.0022 - val_loss: 0.0023 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 5s 332ms/step - loss: 0.0124 - accuracy: 0.0022 - val_loss: 0.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0121 - accuracy: 0.0022 - val_loss: 0.0016 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0119 - accuracy: 0.0022 - val_loss: 0.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0118 - accuracy: 0.0022 - val_loss: 0.0011 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.0117 - accuracy: 0.0022 - val_loss: 9.3405e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 5s 349ms/step - loss: 0.0116 - accuracy: 0.0022 - val_loss: 8.3316e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0116 - accuracy: 0.0022 - val_loss: 7.2168e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 5s 370ms/step - loss: 0.0115 - accuracy: 0.0022 - val_loss: 6.2118e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0115 - accuracy: 0.0022 - val_loss: 5.5631e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0115 - accuracy: 0.0022 - val_loss: 5.0711e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 5s 347ms/step - loss: 0.0115 - accuracy: 0.0022 - val_loss: 4.5879e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0115 - accuracy: 0.0022 - val_loss: 4.4073e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 4.0877e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.7948e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.5083e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 5s 320ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.3349e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 5s 366ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.3113e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 5s 317ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.1284e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.2447e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.0967e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 5s 326ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 3.0254e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 5s 346ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.8864e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 5s 335ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.8219e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.8001e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 5s 319ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7354e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 5s 368ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7465e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 5s 322ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.5492e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 5s 321ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7351e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 5s 350ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7648e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7301e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 5s 348ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7806e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7821e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 5s 353ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.8768e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 5s 323ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.6990e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 5s 363ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.6497e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 5s 324ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.7050e-04 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 5s 319ms/step - loss: 0.0114 - accuracy: 0.0022 - val_loss: 2.6258e-04 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Year: 2022\n",
            "Processing MRL_LINE: M625080\n",
            "      COUNTRY  VISION_OUC CURRENCY MRL_LINE   01   02   03      04      05  \\\n",
            "89         KE  KE01000014      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "384        KE  KE01008100      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "989        KE  KE01000011      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "1344       KE  KE01000024      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "1564       KE  KE01008075      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "...       ...         ...      ...      ...  ...  ...  ...     ...     ...   \n",
            "19041      KE  KE01000030      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "19042      KE  KE01008013      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "19043      KE  KE01008131      KES  M625080  0.0  0.0  0.0   90.00   90.00   \n",
            "19044      KE  KE01008134      KES  M625080  0.0  0.0  0.0  216.97  122.78   \n",
            "19045      KE  KE01008042      KES  M625080  0.0  0.0  0.0    0.00    0.00   \n",
            "\n",
            "            06  ...      08       09      10        11    12  Year  \\\n",
            "89    -1760.00  ... -5324.0  -3850.0 -6072.0       0.0   0.0  2019   \n",
            "384       0.00  ...     0.0      0.0  -500.0    -800.0   0.0  2019   \n",
            "989       0.00  ...     0.0      0.0     0.0       0.0   0.0  2019   \n",
            "1344      0.00  ...     0.0 -20048.0 -4000.0       0.0   0.0  2019   \n",
            "1564      0.00  ...     0.0  -1230.0 -1610.0       0.0   0.0  2019   \n",
            "...        ...  ...     ...      ...     ...       ...   ...   ...   \n",
            "19041     0.00  ...     0.0      0.0     0.0       0.0   0.0  2021   \n",
            "19042     0.00  ...     0.0      0.0     0.0    1500.0   0.0  2021   \n",
            "19043   120.00  ...   120.0     60.0    30.0      30.0  60.0  2021   \n",
            "19044    76.11  ...     0.0      0.0     0.0       0.0   0.0  2021   \n",
            "19045     0.00  ...     0.0      0.0     0.0 -826188.0   0.0  2021   \n",
            "\n",
            "       MRL_Category_Cat1  MRL_Category_Cat2  MRL_Category_Cat3  \\\n",
            "89                     0                  0                  0   \n",
            "384                    0                  0                  0   \n",
            "989                    0                  0                  0   \n",
            "1344                   0                  0                  0   \n",
            "1564                   0                  0                  0   \n",
            "...                  ...                ...                ...   \n",
            "19041                  0                  0                  0   \n",
            "19042                  0                  0                  0   \n",
            "19043                  0                  0                  0   \n",
            "19044                  0                  0                  0   \n",
            "19045                  0                  0                  0   \n",
            "\n",
            "       MRL_Category_Cat4  \n",
            "89                     1  \n",
            "384                    1  \n",
            "989                    1  \n",
            "1344                   1  \n",
            "1564                   1  \n",
            "...                  ...  \n",
            "19041                  1  \n",
            "19042                  1  \n",
            "19043                  1  \n",
            "19044                  1  \n",
            "19045                  1  \n",
            "\n",
            "[75 rows x 21 columns]\n",
            "Processing Year: 2019\n",
            "Creating sequences...\n",
            "432 12\n",
            "Printing X_train and X_test... reshape\n",
            "(409, 24, 1)\n",
            "(1, 12, 1)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_406 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_407\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_406 (Bidirect  (None, 256)              133120    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_406 (Dense)           (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,377\n",
            "Trainable params: 133,377\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/100\n",
            "11/11 [==============================] - 4s 349ms/step - loss: 0.9654 - accuracy: 0.0031 - val_loss: 0.9346 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 4s 321ms/step - loss: 0.9209 - accuracy: 0.0031 - val_loss: 0.8910 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.8776 - accuracy: 0.0031 - val_loss: 0.8487 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 4s 341ms/step - loss: 0.8358 - accuracy: 0.0031 - val_loss: 0.8076 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 4s 356ms/step - loss: 0.7952 - accuracy: 0.0031 - val_loss: 0.7678 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.7557 - accuracy: 0.0031 - val_loss: 0.7292 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 4s 336ms/step - loss: 0.7175 - accuracy: 0.0031 - val_loss: 0.6918 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 4s 357ms/step - loss: 0.6804 - accuracy: 0.0031 - val_loss: 0.6554 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.6443 - accuracy: 0.0031 - val_loss: 0.6200 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 3s 318ms/step - loss: 0.6092 - accuracy: 0.0031 - val_loss: 0.5857 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 4s 365ms/step - loss: 0.5752 - accuracy: 0.0031 - val_loss: 0.5522 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 4s 339ms/step - loss: 0.5420 - accuracy: 0.0031 - val_loss: 0.5198 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.5099 - accuracy: 0.0031 - val_loss: 0.4887 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 4s 349ms/step - loss: 0.4789 - accuracy: 0.0031 - val_loss: 0.4583 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 4s 334ms/step - loss: 0.4488 - accuracy: 0.0031 - val_loss: 0.4287 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 4s 335ms/step - loss: 0.4194 - accuracy: 0.0031 - val_loss: 0.4002 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 4s 346ms/step - loss: 0.3912 - accuracy: 0.0031 - val_loss: 0.3726 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.3640 - accuracy: 0.0031 - val_loss: 0.3462 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 4s 338ms/step - loss: 0.3379 - accuracy: 0.0031 - val_loss: 0.3207 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 4s 358ms/step - loss: 0.3128 - accuracy: 0.0031 - val_loss: 0.2964 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 4s 354ms/step - loss: 0.2889 - accuracy: 0.0031 - val_loss: 0.2732 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 4s 341ms/step - loss: 0.2661 - accuracy: 0.0031 - val_loss: 0.2514 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 4s 355ms/step - loss: 0.2445 - accuracy: 0.0031 - val_loss: 0.2306 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 4s 342ms/step - loss: 0.2240 - accuracy: 0.0031 - val_loss: 0.2108 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.2045 - accuracy: 0.0031 - val_loss: 0.1921 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 4s 375ms/step - loss: 0.1863 - accuracy: 0.0031 - val_loss: 0.1746 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.1692 - accuracy: 0.0031 - val_loss: 0.1582 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.1531 - accuracy: 0.0031 - val_loss: 0.1430 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 4s 362ms/step - loss: 0.1383 - accuracy: 0.0031 - val_loss: 0.1289 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.1244 - accuracy: 0.0031 - val_loss: 0.1159 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 4s 345ms/step - loss: 0.1118 - accuracy: 0.0031 - val_loss: 0.1039 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 4s 354ms/step - loss: 0.1001 - accuracy: 0.0031 - val_loss: 0.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0894 - accuracy: 0.0031 - val_loss: 0.0830 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.0797 - accuracy: 0.0031 - val_loss: 0.0739 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 4s 358ms/step - loss: 0.0709 - accuracy: 0.0031 - val_loss: 0.0656 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 4s 336ms/step - loss: 0.0629 - accuracy: 0.0031 - val_loss: 0.0583 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 4s 337ms/step - loss: 0.0558 - accuracy: 0.0031 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 4s 377ms/step - loss: 0.0493 - accuracy: 0.0031 - val_loss: 0.0457 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 4s 335ms/step - loss: 0.0436 - accuracy: 0.0031 - val_loss: 0.0404 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 3s 317ms/step - loss: 0.0385 - accuracy: 0.0031 - val_loss: 0.0358 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 4s 393ms/step - loss: 0.0341 - accuracy: 0.0031 - val_loss: 0.0317 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 4s 335ms/step - loss: 0.0301 - accuracy: 0.0031 - val_loss: 0.0281 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0266 - accuracy: 0.0031 - val_loss: 0.0250 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 4s 378ms/step - loss: 0.0236 - accuracy: 0.0031 - val_loss: 0.0223 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 3s 320ms/step - loss: 0.0210 - accuracy: 0.0031 - val_loss: 0.0199 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 3s 323ms/step - loss: 0.0187 - accuracy: 0.0031 - val_loss: 0.0180 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 4s 362ms/step - loss: 0.0169 - accuracy: 0.0031 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 4s 339ms/step - loss: 0.0152 - accuracy: 0.0031 - val_loss: 0.0148 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 3s 319ms/step - loss: 0.0138 - accuracy: 0.0031 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0125 - accuracy: 0.0031 - val_loss: 0.0125 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 4s 341ms/step - loss: 0.0115 - accuracy: 0.0031 - val_loss: 0.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 4s 330ms/step - loss: 0.0106 - accuracy: 0.0031 - val_loss: 0.0108 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0099 - accuracy: 0.0031 - val_loss: 0.0102 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 4s 323ms/step - loss: 0.0093 - accuracy: 0.0031 - val_loss: 0.0097 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 4s 347ms/step - loss: 0.0088 - accuracy: 0.0031 - val_loss: 0.0093 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 4s 365ms/step - loss: 0.0083 - accuracy: 0.0031 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.0080 - accuracy: 0.0031 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 4s 339ms/step - loss: 0.0077 - accuracy: 0.0031 - val_loss: 0.0084 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 4s 362ms/step - loss: 0.0074 - accuracy: 0.0031 - val_loss: 0.0082 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 4s 328ms/step - loss: 0.0073 - accuracy: 0.0031 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 4s 339ms/step - loss: 0.0071 - accuracy: 0.0031 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 4s 373ms/step - loss: 0.0070 - accuracy: 0.0031 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 4s 346ms/step - loss: 0.0069 - accuracy: 0.0031 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 4s 337ms/step - loss: 0.0068 - accuracy: 0.0031 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 4s 379ms/step - loss: 0.0067 - accuracy: 0.0031 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 4s 334ms/step - loss: 0.0067 - accuracy: 0.0031 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 3s 323ms/step - loss: 0.0066 - accuracy: 0.0031 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 4s 368ms/step - loss: 0.0066 - accuracy: 0.0031 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 4s 324ms/step - loss: 0.0066 - accuracy: 0.0031 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 3s 321ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 4s 358ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 4s 321ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 4s 325ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 4s 342ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 4s 333ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 4s 340ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 4s 343ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 4s 356ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 4s 348ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 4s 341ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 4s 355ms/step - loss: 0.0065 - accuracy: 0.0031 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            " 6/11 [===============>..............] - ETA: 1s - loss: 0.0062 - accuracy: 0.0052"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PHqR3FKpsmdy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}